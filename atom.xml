<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>扯淡有理</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://naosense.github.io/"/>
  <updated>2025-09-16T02:08:56.242Z</updated>
  <id>https://naosense.github.io/</id>
  
  <author>
    <name>naosense</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>秋天到了跑步者的好日子来了</title>
    <link href="https://naosense.github.io/2025/09/16/%E7%A7%8B%E5%A4%A9%E5%88%B0%E4%BA%86%E8%B7%91%E6%AD%A5%E8%80%85%E7%9A%84%E5%A5%BD%E6%97%A5%E5%AD%90%E6%9D%A5%E4%BA%86/"/>
    <id>https://naosense.github.io/2025/09/16/秋天到了跑步者的好日子来了/</id>
    <published>2025-09-16T09:40:03.000Z</published>
    <updated>2025-09-16T02:08:56.242Z</updated>
    
    <content type="html"><![CDATA[<p>又逢秋节至，咱跑步者的好日子来了。春天冷，夏天热，秋高气爽跑起来就是爽啊！</p><p>今年配速快了一些，心率和以往大差不差，高了一点，从5月以来基本维持60%左右的出勤率，也就是一个月跑个18次左右，因为只有工作日跑，间或偷个懒(^_−)，总共跑了300多公里了，争取年底跑到600公里！同志们都加油跑起来啊！</p><p><img src="garmin.jpeg" alt="garmin"></p><p><img src="miles.jpeg" alt="miles"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;又逢秋节至，咱跑步者的好日子来了。春天冷，夏天热，秋高气爽跑起来就是爽啊！&lt;/p&gt;
&lt;p&gt;今年配速快了一些，心率和以往大差不差，高了一点，从5月以来基本维持60%左右的出勤率，也就是一个月跑个18次左右，因为只有工作日跑，间或偷个懒(^_−)，总共跑了300多公里了，争取年
      
    
    </summary>
    
    
      <category term="跑步" scheme="https://naosense.github.io/tags/%E8%B7%91%E6%AD%A5/"/>
    
      <category term="减肥" scheme="https://naosense.github.io/tags/%E5%87%8F%E8%82%A5/"/>
    
  </entry>
  
  <entry>
    <title>春风得意马蹄疾，今日回看梦黄粱</title>
    <link href="https://naosense.github.io/2025/01/11/%E6%98%A5%E9%A3%8E%E5%BE%97%E6%84%8F%E9%A9%AC%E8%B9%84%E7%96%BE%EF%BC%8C%E4%BB%8A%E6%97%A5%E5%9B%9E%E7%9C%8B%E6%A2%A6%E9%BB%84%E7%B2%B1/"/>
    <id>https://naosense.github.io/2025/01/11/春风得意马蹄疾，今日回看梦黄粱/</id>
    <published>2025-01-11T10:35:43.000Z</published>
    <updated>2025-09-16T02:08:42.975Z</updated>
    
    <content type="html"><![CDATA[<p>2014年，本书出版的年份，正是中美云淡风轻的时候，当时批毛之风盛行，因为什么呢？书中有句话印象深刻：“邓的理念是融入欧美经济体系”。经过30年的融入，中国正是春风得意的时候，包括作者在内的教授们以为中国已经走在正确的道路上，已经登堂入室了。可是美国这位好老师，偏偏爱教育人，狠狠得给了这帮人一记响亮的耳光，告诉这帮人，全球化你们还真信呢。要不毛泽东老是强调反面教材，原因大概是反面教材教育人它是真疼啊！</p><p>毛泽东思想是斗争的哲学，是在实践中流血流汗得来得，是这些十指不沾阳春水，脚不曾踏过实地的教授们天生所排斥的。这些办公室研究员，客厅思想家写出来得东西天生带有自身的奴颜媚骨和想当然。他们分不清理想与现实，总以为这个世界是一个童话，你好我好大家好就可以了，不要那些打打杀杀。</p><p>总结下来，这是一本一名既得利益者为一群既得利益者写就得辩护书，盛名之下其实难副。附录尚可一读，其余都是春风吹又生的陈词滥调。</p><p>最后提醒一下，冯骥推荐得是《筚路蓝缕：计划经济在中国》，不是这本。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2014年，本书出版的年份，正是中美云淡风轻的时候，当时批毛之风盛行，因为什么呢？书中有句话印象深刻：“邓的理念是融入欧美经济体系”。经过30年的融入，中国正是春风得意的时候，包括作者在内的教授们以为中国已经走在正确的道路上，已经登堂入室了。可是美国这位好老师，偏偏爱教育人
      
    
    </summary>
    
    
      <category term="读后感" scheme="https://naosense.github.io/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"/>
    
  </entry>
  
  <entry>
    <title>文明的第一要义是生存</title>
    <link href="https://naosense.github.io/2025/01/11/%E6%96%87%E6%98%8E%E7%9A%84%E7%AC%AC%E4%B8%80%E8%A6%81%E4%B9%89%E6%98%AF%E7%94%9F%E5%AD%98/"/>
    <id>https://naosense.github.io/2025/01/11/文明的第一要义是生存/</id>
    <published>2025-01-11T07:49:58.000Z</published>
    <updated>2025-09-16T02:08:42.975Z</updated>
    
    <content type="html"><![CDATA[<p>拉丁美洲的历史总让人看的有一种无力感，就像一架进入尾旋的飞机，有人尝试改出，但功亏一篑，有人虎头蛇尾，半途而废，还有人冷眼旁观，事不关己……最后眼睁睁地看着它的高度越来越低，直到坠毁。</p><p>拉美被发现的太早，自己还没有充分发展，拉美被发现的又太晚，被发现时已落后太远。如果留给它充足的时间发展，也许它也会有自己的秦始皇，也许没有秦始皇也会有晋始皇，就像某些历史唯物论半瓶醋声称的那样。但是多少事，从来急，历史不是无菌的培养皿，文明之间也会弱肉强食，有些事一旦失去时机，就再也没有做的可能了。因为文明一旦消失，别说秦始皇就是李狗蛋也不会有了。现在，阿兹特克没人说话了，印加也没人说话了……</p><p>拉美，不幸的拉美，一个起步太晚的文明，与世界发生联系时尚处于襁褓之中，在凛冽的现实环境中迅速的败下阵来以至于行将消亡。</p><p>文明的第一要义是生存，否则一切都是泡影。也许拉美还要在黑暗中摸索许多年才能找到自己的路，也许几百年，也许几千年，也许是接近于无限的永远。只是作为一个数学概念有意义的无限，对于一个文明、一个人，又有什么意义呢？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;拉丁美洲的历史总让人看的有一种无力感，就像一架进入尾旋的飞机，有人尝试改出，但功亏一篑，有人虎头蛇尾，半途而废，还有人冷眼旁观，事不关己……最后眼睁睁地看着它的高度越来越低，直到坠毁。&lt;/p&gt;
&lt;p&gt;拉美被发现的太早，自己还没有充分发展，拉美被发现的又太晚，被发现时已落后太
      
    
    </summary>
    
    
      <category term="读后感" scheme="https://naosense.github.io/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"/>
    
  </entry>
  
  <entry>
    <title>第12章 数据系统的未来</title>
    <link href="https://naosense.github.io/2024/02/02/%E7%AC%AC12%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%9C%AA%E6%9D%A5/"/>
    <id>https://naosense.github.io/2024/02/02/第12章 数据系统的未来/</id>
    <published>2024-02-02T17:14:57.000Z</published>
    <updated>2025-09-16T02:08:42.978Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据集成">数据集成</h2><p>派生数据与分布式事务通过不同的方式达到了类似的目标。分布式事务通过锁机制进行互斥来决定写操作的顺序，而CDC和事件源使用日志进行排序。分布式事务使用原子提交来确保更改只生效一次，而基于日志的系统通常基于确定性重试和幂等性。</p><p>派生数据允许逐步演变。想重建数据集，无需采用高风险的陡然切换。而是在同一个基础数据上的两个独立视图来同时维护新老两种架构。逐步将少量用户迁移到新视图中，以测试性能检测错误。最后，所有用户迁移完，放弃旧视图。</p><p>lambda架构</p><p>核心思想是将数据看成一个个不可变的事件，基于这些总事件，派生出读优化的视图。建议运行两套系统：一个批处理，一个流处理。批处理产生精确的全量视图，流处理产生及时的增量视图。</p><p>这样结合了两套系统的优点：批处理简单，不易出错，流处理不可靠，难以容错，但流处理可以使用快速的近似算法。</p><p>最近的发展是将批处理和流处理在同一个系统中实现，即所谓的kappa架构。</p><h2 id="分拆数据库">分拆数据库</h2><p>整个组织的数据流就像一个巨大的数据库。每当批处理、流或ETL将数据从一个位置传输到另一个位置，就类似数据库子系统需要保持索引或实体化视图至最新状态。流处理，批处理就像触发器。没有统一的数据模型或存储格式适用于所有的访问模式，最终会统一为两种途径：</p><ul><li><p>联合数据库：统一读端</p><p>为各种各样的底层存储引擎和处理方法提供一个统一的查询结构：一种称为联合数据库或聚合存储的方法。</p></li><li><p>分离式数据库：统一写端</p><p>跨系统的同步写。</p></li></ul><p>传统的同步写依赖分布式事务，但是具有幂等写入的异步事件日志是一种更健壮的方法。</p><ul><li>在系统级别，异步事件流使得组件终端或性能下降时表现更稳健。</li><li>在人员角度，分离式数据系统使得不同的团队可以独立的开发、改进和维护不同的软件和服务，可以更专业的专注于自己的领域。</li></ul><p>分离和组合的目的并不是替代传统数据库，而是为了组合不同的系统，结合每个系统的优点去满足自己的需求。</p><p>流式处理与服务</p><p>前者是单向的，异步的，后者是双向的，同步的。假设客户正在购买一种商品，这种商品以某一种货币定价，但需要另一种货币支付。两种方式的实现：</p><ol><li>对于微服务，同步查询汇率服务，以获取特定货币的当前汇率。</li><li>对于数据流，会预先订阅汇率变更流，并在本地数据库记录当前汇率。</li></ol><p>但是要注意事件依赖，如果要重演当初的购买行为，汇率必须得是当时的。</p><p>写路径与读路径</p><p><img src="write_path_and_read_path.jpeg" alt="write path and read path"></p><p>写路径与读路径涵盖了数据的整个过程。写路径和读路径在派生数据集上交会，某种程度上，它是写入时需完成的工作量与读取时需完成的工作量之间的一种平衡。从这个角度看，缓存、索引和视图主要是调整读写路径之间的边界。</p><h2 id="端到端的正确性">端到端的正确性</h2><h3 id="强制约束">强制约束</h3><p>一致性包含两个方面：</p><ul><li><p>时效性</p><p>意味着确保用户观察到系统的最新状态。暂时的，最终通过等待和再次尝试来解决。</p></li><li><p>完整性</p><p>意味着避免数据损坏，即没有数据丢失，也没有互相矛盾或错误的数据。永久的，需要专门的检查和修理。</p></li></ul><h3 id="宽松的约束">宽松的约束</h3><p>为了性能或可用性通常会采用。</p><ul><li>如果两个人注册了相同的用户名或预订了同一个座位，则可以向其中一个发送道歉消息。这种纠正错误的措施被称为补偿性事务。</li><li>如果订购的商品超出库存，可以追加补充库存，但需要为延误发货道歉，并提供折扣。</li><li>如果有人提款额比他们账户中的钱还多，银行可以向他们收取透支费用。</li></ul><p>在许多商业环境中，实际上可以接受的是暂时性违反约束，稍后通过道歉流程来修复，关键是道歉的成本有多高。</p><h3 id="信任，但要确认">信任，但要确认</h3><p>也就是允许系统出错，但是要及时的发现和修复。</p><p>加密工具来证明系统的完整性，比如加密货币、区块链和分布式账本。密码审计和完整性检查常常依赖默克尔树（Merkle Tree）。</p><p>检查数据完整性也被称为审计。</p><h2 id="做正确的事">做正确的事</h2><p>技术是工具而不是目的，要用技术造福人类。本节讨论了一些开发问题，比如偏见和歧视、信息孤岛导致的囚笼效应，用户隐私保护等话题。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;数据集成&quot;&gt;数据集成&lt;/h2&gt;
&lt;p&gt;派生数据与分布式事务通过不同的方式达到了类似的目标。分布式事务通过锁机制进行互斥来决定写操作的顺序，而CDC和事件源使用日志进行排序。分布式事务使用原子提交来确保更改只生效一次，而基于日志的系统通常基于确定性重试和幂等性。&lt;/
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第11章 流处理系统</title>
    <link href="https://naosense.github.io/2024/01/30/%E7%AC%AC11%E7%AB%A0%20%E6%B5%81%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F/"/>
    <id>https://naosense.github.io/2024/01/30/第11章 流处理系统/</id>
    <published>2024-01-30T11:32:20.000Z</published>
    <updated>2025-09-16T02:08:42.978Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>一个可用的复杂系统总是从可用的简单系统演进来的。反过来这话也是正确的：从零开始设计的复杂系统从来都用不了，也没办法把它变成可用。</p><p>——John Gal，《系统学》（1975）</p></blockquote><h2 id="发送事件流">发送事件流</h2><h3 id="消息系统">消息系统</h3><p>发送事件通知的常用方式。</p><ul><li>如果生产者发送消息的速度快于消费者处理，会发生什么？</li><li>如果节点崩溃或暂时离线，是否会有消息丢失？</li></ul><h4 id="生产者与消费者直接消息传递">生产者与消费者直接消息传递</h4><p>即无代理的方式。这种方式当消费者离线时会丢失消息。</p><p>常见场景：</p><ul><li>UDP组播广泛应用在金融行业，比如股票市场等低延迟场景。</li><li>无代理的消息库，如ZeroMQ和nanomsg，通过TCP或IP多播实现发布/订阅消息传递。</li><li>StatsD和Brubeck使用UDP手机网络中所有机器的指标并进行监控。</li><li>网络上公开服务，生产者直接发出HTTP或RPC请求将消息推送给消费者。</li></ul><h4 id="消息代理（无日志）">消息代理（无日志）</h4><p>本质上是一种针对消息流处理而优化的数据库。常见产品Rabbit MQ、ActiveMQ等。</p><p>只能消费订阅之后的消息，也就是历史的消息已经不能消费了。</p><h4 id="基于日志的消息存储">基于日志的消息存储</h4><p>将历史的消息存储为日志形式。代表产品Kafka、Twitter DistrbutedLog。</p><h2 id="数据库与流">数据库与流</h2><p>事件是成功的命令。一个请求到来时最初是一个命令，它可能失败，或违反某种约束。一旦它成功，它就是一个事件了。</p><p>变更数据捕获（changed data capture，CDC）是一种设计理念。不是记录数据的当前状态，而是数据变化的过程。</p><p>事件溯源（event source）是一种强大的数据建模技术，是对CDC思想的一种应用。事件溯源使得应用程序随着时间的推移更容易演化，更安全，杜绝了直接覆盖数据的情形，更容易理解发生了什么来帮助调试分析。比如用户加购一个商品后又删除，使用事件溯源就会捕获到更多的细节，用户可能将来会买，或者找到了替代品。</p><h2 id="流处理">流处理</h2><h3 id="流处理的使用场景">流处理的使用场景</h3><p>复杂事件处理（Complex Event Processing，CEP）可以在流中搜索特定的模式，类似于正则表达式。查询和数据的关系在CEP和普通数据库是反过来的。在普通数据库中，数据是长期存储的，查询是临时的，一旦查询完，查询就没了。而在CEP中，查询是长期的，输入流中的事件不断流过匹配查询。常见实现Esper、IBM Info Sphere Streams、Apama等。</p><p>流分析与CEP界限有些模糊。作为一般规则，分析往往不太关心找到特定的事件序列，而更多地面向大量事件的累积效果和统计指标。例如：</p><ul><li>测量某种类型事件的速率。</li><li>计算一段时间内某个值的滚动平均值。</li><li>将当前的统计数据与之前的时间间隔进行比较。</li></ul><p>流分析有时使用概率算法，比如布隆过滤器，基数统计的HyperLogLog，但是流不等于就是概率的，不精确的。</p><p>Actor与流：</p><ul><li>Actor是管理通信模块的并发和分布式执行的机制，而流处理是数据管理技术。</li><li>Actor之间交流往往是短暂的，并且一对一，而事件日志是持久的，多用户的。</li><li>Actor可以以任意方式进行通信（包括循环请求/响应模式），但流处理器通常设置在非循环流水线中，其中每个流是一个特定作业的输出，并且从一组定义明确的输入流派生而来。</li></ul><h3 id="流的时间问题">流的时间问题</h3><p>事件时间与处理时间</p><p>使用事件时间得确定什么时候结束，使用处理事件可能导致事件错乱，处理事件的顺序和事件时间不一样。</p><p>窗口类型：</p><ul><li><p>轮转窗口</p><p>长度固定，每个事件都属于一个窗口。比如一个一分钟窗口，10:03:00~10:03:59分到一个窗口，10:04:00~10:04:59是下一个窗口。</p></li><li><p>跳跃窗口</p><p>也具有固定长度，但是允许重叠。例如一个五分钟窗口，设定跳跃值为一分钟，10:03:00～10:07:59为一个窗口，下一个窗口为10:04:00～10:08:59，以此类推。</p></li><li><p>滑动窗口</p><p>包含某个间隔内发生地所有事件。例如，一个五分钟的滑动窗口将包括10:03:39～10:08:12的事件，因为他们相距不到五分钟。可以通过保留按时间排序的事件缓冲区并从移除旧事件来实现。</p></li><li><p>会话窗口</p><p>没有固定的持续时间，而是通过将同一用户在时间上紧密相关的所有事件分组在一起而定义的，一旦用户在一段事件内处于非活动状态，则窗口结束。</p></li></ul><h3 id="流式join">流式join</h3><ul><li>流和流join</li><li>流和表join</li><li>表和表join</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;一个可用的复杂系统总是从可用的简单系统演进来的。反过来这话也是正确的：从零开始设计的复杂系统从来都用不了，也没办法把它变成可用。&lt;/p&gt;
&lt;p&gt;——John Gal，《系统学》（1975）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;发送事
      
    
    </summary>
    
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>红楼梦人物关系图谱</title>
    <link href="https://naosense.github.io/2024/01/23/%E7%BA%A2%E6%A5%BC%E6%A2%A6%E4%BA%BA%E7%89%A9%E5%85%B3%E7%B3%BB%E5%9B%BE%E8%B0%B1/"/>
    <id>https://naosense.github.io/2024/01/23/红楼梦人物关系图谱/</id>
    <published>2024-01-23T12:56:22.000Z</published>
    <updated>2025-09-16T02:08:43.018Z</updated>
    
    <content type="html"><![CDATA[<p>红楼梦中人物太多了，第一次读过以至于都没意识到宝玉和黛玉竟是表兄妹。最近重读，读了没几回，又迷糊了。索性系统整理了下里面人物的关系，以备后面查询。并不是面面俱到，但是主要的人物应该都在里面了，需要的同学自行取用。</p><img width="1000" alt="红楼梦人物" src="红楼梦人物.jpeg"><h2 id="宁国公（长子）">宁国公（长子）</h2><h3 id="贾代化（长子）">贾代化（长子）</h3><h4 id="贾敷（长子，早夭）">贾敷（长子，早夭）</h4><h4 id="贾敬（次子）">贾敬（次子）</h4><h5 id="贾珍（儿子）">贾珍（儿子）</h5><h6 id="尤氏（妻子）">尤氏（妻子）</h6><h6 id="贾蓉（儿子）">贾蓉（儿子）</h6><ul><li>秦可卿（妻子）<ul><li>秦业（父亲）</li><li>秦钟（弟弟）<ul><li>智能（恋人）</li></ul></li><li>宝珠（义女）</li></ul></li></ul><h6 id="贾蔷（侄子）">贾蔷（侄子）</h6><ul><li>龄官（恋人）</li></ul><h5 id="贾惜春（女儿）">贾惜春（女儿）</h5><h6 id="入画（丫鬟）">入画（丫鬟）</h6><h2 id="荣国公（次子）">荣国公（次子）</h2><h3 id="贾代善（长子）">贾代善（长子）</h3><h4 id="史太君（妻子）">史太君（妻子）</h4><h5 id="鸳鸯（丫鬟）">鸳鸯（丫鬟）</h5><h4 id="贾赦（长子）">贾赦（长子）</h4><h5 id="邢夫人（妻子）">邢夫人（妻子）</h5><h5 id="贾琏（儿子）">贾琏（儿子）</h5><h6 id="王熙凤（妻子）">王熙凤（妻子）</h6><h6 id="尤二姐（妾）">尤二姐（妾）</h6><ul><li>尤三姐（妹妹）<ul><li>柳湘莲（恋人）</li></ul></li></ul><h6 id="巧姐（女儿）">巧姐（女儿）</h6><h6 id="平儿（丫鬟）">平儿（丫鬟）</h6><h5 id="贾迎春（女儿）">贾迎春（女儿）</h5><h6 id="孙绍祖（丈夫）">孙绍祖（丈夫）</h6><h6 id="司棋（丫鬟）">司棋（丫鬟）</h6><h4 id="贾政（次子）">贾政（次子）</h4><h5 id="王夫人（妻子）">王夫人（妻子）</h5><h6 id="金钏（丫鬟）">金钏（丫鬟）</h6><h5 id="周姨娘（妾）">周姨娘（妾）</h5><h5 id="赵姨娘（妾）">赵姨娘（妾）</h5><h5 id="贾珠（长子，早夭）">贾珠（长子，早夭）</h5><h6 id="李纨（妻子）">李纨（妻子）</h6><ul><li>李绮（堂妹）<ul><li>甄宝玉（丈夫）</li></ul></li><li>李纹（堂妹）</li></ul><h6 id="贾兰（儿子）">贾兰（儿子）</h6><h5 id="贾元春（长女）">贾元春（长女）</h5><h6 id="抱琴（丫鬟）">抱琴（丫鬟）</h6><h5 id="贾宝玉（次子）"><strong>贾宝玉（次子）</strong></h5><ul><li>袭人（丫鬟）</li><li>晴雯（丫鬟）</li><li>麝月（丫鬟）</li><li>秋纹（丫鬟）</li></ul><h5 id="贾探春（庶女，母赵姨娘）">贾探春（庶女，母赵姨娘）</h5><h6 id="侍书（丫鬟）">侍书（丫鬟）</h6><h5 id="贾环（庶子，母赵姨娘）">贾环（庶子，母赵姨娘）</h5><h4 id="贾敏（女儿）">贾敏（女儿）</h4><h5 id="林如海（丈夫）">林如海（丈夫）</h5><h5 id="林黛玉（女儿）"><strong>林黛玉（女儿）</strong></h5><h6 id="雪雁（丫鬟）">雪雁（丫鬟）</h6><h6 id="紫鹃（丫鬟）">紫鹃（丫鬟）</h6><h6 id="贾雨村（老师）">贾雨村（老师）</h6><ul><li>娇杏（妻子）</li></ul><h3 id="贾代儒">贾代儒</h3><h4 id="贾瑞父母（亡故）">贾瑞父母（亡故）</h4><h5 id="贾瑞（儿子）">贾瑞（儿子）</h5><h2 id="史家">史家</h2><h3 id="史太君">史太君</h3><h4 id="史鼐（内侄）">史鼐（内侄）</h4><h5 id="史湘云（侄女）">史湘云（侄女）</h5><h2 id="王家">王家</h2><h3 id="王公">王公</h3><h4 id="王子腾（儿子）">王子腾（儿子）</h4><h4 id="王夫人（女儿）">王夫人（女儿）</h4><h4 id="薛姨妈（女儿）">薛姨妈（女儿）</h4><h4 id="凤姐之父（儿子）">凤姐之父（儿子）</h4><h5 id="王仁（儿子）">王仁（儿子）</h5><h5 id="王熙凤（女儿）">王熙凤（女儿）</h5><h4 id="刘姥姥（女婿狗儿祖父连过宗）">刘姥姥（女婿狗儿祖父连过宗）</h4><h2 id="薛家">薛家</h2><h3 id="薛公">薛公</h3><h4 id="宝钗祖父">宝钗祖父</h4><h5 id="薛宝琴之父">薛宝琴之父</h5><h6 id="薛蝌（儿子）">薛蝌（儿子）</h6><ul><li>邢岫烟（妻子）</li></ul><h6 id="薛宝琴（女儿）">薛宝琴（女儿）</h6><h5 id="薛宝钗之父">薛宝钗之父</h5><h6 id="薛姨妈（妻子）">薛姨妈（妻子）</h6><h6 id="薛蟠（儿子）">薛蟠（儿子）</h6><ul><li>夏金桂（妻子）</li><li>香菱（妾）<ul><li>甄士隐（父亲）</li></ul></li></ul><h6 id="薛宝钗（女儿）"><strong>薛宝钗（女儿）</strong></h6>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;红楼梦中人物太多了，第一次读过以至于都没意识到宝玉和黛玉竟是表兄妹。最近重读，读了没几回，又迷糊了。索性系统整理了下里面人物的关系，以备后面查询。并不是面面俱到，但是主要的人物应该都在里面了，需要的同学自行取用。&lt;/p&gt;
&lt;img width=&quot;1000&quot; alt=&quot;红楼梦
      
    
    </summary>
    
    
      <category term="红楼梦" scheme="https://naosense.github.io/tags/%E7%BA%A2%E6%A5%BC%E6%A2%A6/"/>
    
  </entry>
  
  <entry>
    <title>第10章 批处理系统</title>
    <link href="https://naosense.github.io/2024/01/22/%E7%AC%AC10%E7%AB%A0%20%E6%89%B9%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F/"/>
    <id>https://naosense.github.io/2024/01/22/第10章 批处理系统/</id>
    <published>2024-01-22T15:10:19.000Z</published>
    <updated>2025-09-16T02:08:42.978Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>通过弄清数据的来龙去脉，来理清复杂的系统架构，是本书的宗旨。</p></blockquote><p>三种系统：</p><ul><li><p>在线服务（或称在线系统）</p><p>服务等待客户端请求或指令的到达。当收到请求或指令时，服务试图尽快的处理它，并发挥响应。响应时间和可用性是衡量标准。</p></li><li><p>批处理（或称离线系统）</p><p>接收大量的输入数据，运行一个作业来处理数据，并产生输出数据。衡量标准是吞吐量。</p></li><li><p>流处理（或称近实时系统）</p><p>流处理介于在线与离线之间。与批处理类似，流处理处理输入并产生输出。但是，流处理作业在事件发生不久就可对事件进行处理。</p></li></ul><p>linux命令是单机版的批处理，map-reduce是分布式的批处理。unix工具使用stdin和stdout作为输入输出，MapReduce作业使用HDFS（Hadoop Distributed File System）分布式文件系统读写文件。</p><p>除HDFS外，还有GlusterFS和Quantcast File System（QFS）。注入Amazon S3，Azure Blob存储和Open Swift对象存储服务也有相似之处。</p><p>HDFS在每台机器上都有一个守护进程，并开放一个网络服务以便其他节点访问存储在该机器上的文件。名为NameNode的中央服务器会跟踪哪个文件存储在哪台机器上。</p><p>批处理的输出：</p><ul><li>生成搜索索引。尽管如今Google不再使用MapReduce构建索引，但是MapReduce仍是构建Lucene和Solr的好方法。</li><li>构建机器学习系统。比如分类器（如垃圾邮件过滤，异常检测，图像识别）和推荐系统（可能认识的人，可能感兴趣的产品）。</li></ul><p>MapReduce虽然在模型抽象上比较简单，但是使用起来却很不方便。例如，你需要从头开始实现全部join算法。</p><p>MapReduce在物化（将中间状态写入文件的过程）的过程中存在如下问题：</p><ul><li>前面的作业完成之后，后面的作业才能开始。</li><li>Mapper通常是冗余的。它们通常是读取前一个reducer写入的文件，并为下一个分区和排序阶段做准备。通常可以和reducer放在一起。</li><li>中间状态会复制到多个节点。</li></ul><p>为了解决这些问题，Spark、Tez和Flink等数据流引擎应运而生。它们有一个共同点：将整个工作流作为一个作业完成，而不是把它分解为独立的子作业。同时也不严格区分map和reduce角色，而是以函数运算符进行组合。优点：</p><ul><li>排序等昂贵的操作只在需要的地方进行，而不是在map和reduce之间默认发生。</li><li>没有不必要的map，可以合并到前一个reduce中。</li><li>所有join和数据依赖都是明确声明的，调度器知道哪些是必需的，因此可以进行本地优化。比如将使用某些数据的任务放在生成数据的机器上，避免网络复制。</li><li>将中间状态保存在内存或本地磁盘就够了，比写入HDFS更省IO。</li><li>运算符在输入准备就绪后立即开始，不用等待上一阶段全部完成。</li><li>MapReduce每个任务启动一个JVM，现在可以重用JVM。</li></ul><p>Spark、Flink和Tez为了避免写入中间状态，同时失败了能够重新开始计算，必须在框架层追踪给定数据是如何计算的，使用了哪个输入分区以及应用了哪个运算符。Spark使用弹性分布式数据集（Resilient Distributed Dataset，RDD）来追踪数据的祖先，Flink对运算符状态建立检查点。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;通过弄清数据的来龙去脉，来理清复杂的系统架构，是本书的宗旨。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;三种系统：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在线服务（或称在线系统）&lt;/p&gt;
&lt;p&gt;服务等待客户端请求或指令的到达。当收到请求或指令时，服务试
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第9章 一致性与共识</title>
    <link href="https://naosense.github.io/2024/01/11/%E7%AC%AC9%E7%AB%A0%20%E4%B8%80%E8%87%B4%E6%80%A7%E4%B8%8E%E5%85%B1%E8%AF%86/"/>
    <id>https://naosense.github.io/2024/01/11/第9章 一致性与共识/</id>
    <published>2024-01-11T17:25:39.000Z</published>
    <updated>2025-09-16T02:08:43.015Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一致性保证">一致性保证</h2><p>分布式一致性与事务隔离级别有相似之处。但总体有着显著区别：事务隔离是为了处理并发执行事务时的各种临界条件，而分布式一致性则主要针对延迟和故障等问题来协调副本之间的状态。</p><h2 id="可线性化">可线性化</h2><p><strong>所谓线性化，就是让一个系统看起来好像只有一个数据副本，且所有操作都是原子的</strong>。可线性化是最强的一致性保证。</p><p>例如一个非线性化的体育网站。Alice和Bob坐在同一个房间里各自观看自己的手机，焦集的等待2014年FIFA世界杯决赛的结果。Alice率先看到了比赛结果，然后兴奋地告诉了Bob。结果，Bob刷新之后发现比赛还没有结束。</p><p><img src="nonlinear_sport_website.jpeg" alt="nonlinear sport website"></p><p>对于Dynamo风格的数据库，即时使用了严格的quorum（法定人数），在网络条件不好的情况下仍然不满足线性化。比如x初始值为0，写客户端向三个副本（n=3，w=3）发送写请求将x更新为1。客户端A在一个节点读到了新值1，客户端B在A读取之后读取，反而收到的都是旧值0。</p><p><img src="only_quorum_is_not_enough.jpeg" alt="only quorum is not enough"></p><h3 id="CAP理论">CAP理论</h3><p>不仅仅主从复制和多主复制，即使在一个数据中心内部，只要有不可靠的网络，都会发生违背线性化的风险。</p><p>CAP理论由Eric Brewer于2000年正式命名，最初是作为一个经验法则被提出，并没有准确的定义，它的含义是“在网络分区的情况下，选择一致性还是可用性”，目的是帮助大家探讨数据库设计的权衡之道，对于具体的系统设计来说意义不大。</p><ul><li>如果要求线性化，由于网络方面的问题，某些副本断开之后，就必须等待网络修复，或者直接返回错误。无论哪种方式，服务都是不可用。</li><li>如果不要求线性化，断开连接后，每个副本可以独立处理请求例如写操作（多主复制）。此时服务可用，但结果行为不符合线性化。</li></ul><h3 id="可线性化与网络延迟">可线性化与网络延迟</h3><p>当前很少有系统真正满足线性化，原因是性能。比如现在多核CPU上的内存：如果某个CPU核上运行的线程修改了一个内存地址，紧接着另一个CPU上的线程尝试读取，则系统无法保证可以读到刚刚写入的值，除非使用了内存屏障或fence指令。</p><p>Attiya和Welch证明了如果想要满足线性化，那么读、写请求的响应时间至少与网络中延迟成正比。</p><h2 id="顺序保证">顺序保证</h2><h3 id="顺序与因果关系">顺序与因果关系</h3><p>如果系统服从因果关系所规定的顺序，称之为<strong>因果一致性</strong>。</p><p><strong>全序</strong>关系支持任意两个元素之间进行比较。比如自然数符合全序关系。还有一些元素在某些情况下可以比较，在某些情况下不可比较，称之为<strong>偏序</strong>。比如集合，当集合有包含关系时，可以比较，否则不可比较。</p><p>因果关系并非全序，可线性化强于因果一致性。</p><h3 id="序列号排序">序列号排序</h3><p>虽然因果关系很重要，但是在实际系统中跟踪这种关系却不切实际。在许多系统中，在写入之前会先读取大量的数据，系统无法了解之后的写入是依赖全部读取内容，还是部分。</p><p>一个更好的方法：使用序列号或时间戳（可以是逻辑时间戳）。这样所有的操作可以进行全序排序，从而捕获了所有的因果关系，同时强加了比因果关系更为严格的顺序性。</p><h4 id="非因果序列发生器">非因果序列发生器</h4><ul><li>每个节点都独立产生自己的一组序列号。比如一个产生奇数，一个产生偶数。</li><li>物理时钟。</li><li>给每个节点分配序列号区间范围。比如节点A为0~1000，节点B是1001~2000。</li></ul><h4 id="Lamport时间戳">Lamport时间戳</h4><p>每个节点都有一个唯一的标识符，且每个节点都有有一个计数器记录请求总数。它的形式是一个键值对：（计数器，节点ID）。可以解决上面三种序列号都可能与因果不一致的情况。</p><p>假设事件A和事件B的计数器为C(A)和C(B)，那么如果A在B之前发生，那么必有C(A) &lt; C(B)，反过来，如果C(A) &lt; C(B)，A并不一定发生在B之前。也就是说，时间戳与因果关系是必要不充分的。注意这里说的A发生在B之前是在说因果关系，来自于happen-before的直译，并不是现实中物理时间上发生的意义。</p><p>比如下面图中节点1事件(1, 1)小于节点2的事件(2, 2)，但是二者并没有因果关系，而是一种并行关系。</p><p><img src="lamport_timestamp.jpeg" alt="lamport timestamp"></p><p>如果C(A) = C(B)，A和B是什么关系呢？答案是并行关系。比如上面的(1, 1)和(1, 2)、(6, 1)和(6, 2)。</p><p>也就是说，Lamport时间戳使得所有的事件都能比较，即全序，包括那些并行的事件，以及具有因果关系的事件。这样的结果是因果关系的事件先后顺序确实都没问题，但是并行事件实际发生顺序可能是错的。比如节点1事件(1, 1)的lamport时间戳小于节点2的事件(2, 2)，但是在物理时间上，后者可能先于前者发生。</p><h4 id="时间戳排序依然不够">时间戳排序依然不够</h4><p>为了实现用户名唯一性约束这样的目标，仅仅对操作进行全序排列还是不够的，还需要知道这些操作是否发生、发生时间等。因为操作是分布式的，在当前节点用户名创建的这一瞬间，你需要收集到在其他节点上是否有其他请求也在创建同一个用户。</p><p>要想知道什么时候全序关系已经确定就需要“全序关系广播”。</p><h3 id="全序关系广播">全序关系广播</h3><p>全序关系广播常指节点之间交换消息的某种协议。它要求满足两个基本安全属性：</p><ul><li>可靠发送：没有消息丢失，如果消息发送到了某一个节点，则它一定要发送到所有节点。</li><li>严格有序：消息总是以相同的顺序发送到每个节点。</li></ul><p>像ZooKeeper和etcd这样的共识服务实际上就实现了全关系序广播。</p><h4 id="采用全序关系广播实现线性化存储">采用全序关系广播实现线性化存储</h4><p>全序关系与线性化并不等同，但是关系密切。全序广播是异步的，保证以固定的顺序可靠的传递，但不能保证何时传递。相反，线性化是一种最近的保证，读取保证看到最新写入的值。</p><p>理解全序关系广播的一种方式是将其看作日志。传递消息就像追加方式更新日志。以全序关系广播以追加日志的方式来实现原子比较-设置操作（创建用户）：</p><ol><li>在日志中追加一条消息，并指明想要的用户名。</li><li>读取日志，将其广播给所有节点，并等待回复。</li><li>检查是否有任何消息生成用户名已被占用。如果是中止操作，否则成功获得该用户名。</li></ol><p>此过程实现了线性化写入，却无法保证线性化读取，即读取时可能是旧值。具体来说，这里只提供了顺序一致性，也称为时间一致性，弱于线性化保证。为了同时满足线性化读取，有以下几个方案：</p><ul><li>可以采用追加的方式将读请求排序、广播，然后各个节点获取该日志，当本节点收到消息时才执行真正的读操作。消息在日志中的位置已经决定了读取发生的时间点。etcd的quorum读取和这个思路相似。</li><li>如果日志允许你以线性化的方式获取最新日志的位置，则查询该位置，等待直到该位置之前的所有条目都已经发送给你，接下来再执行读取。这与ZooKeeper的sync()操作思路相同。</li><li>可以从同步更新的副本上进行读取，这样确保总是读到最新值。这种技术可以用于<strong>链式复制</strong>。</li></ul><p>（没看懂前面两点的不同）</p><h4 id="采用线性化存储实现全序关系广播">采用线性化存储实现全序关系广播</h4><p>也可以反过来，通过线性化实现全序广播。</p><p>最简单的方法是假设有一个线性化的寄存器来存储一个计数，然后使其支持原子自增-读取操作或者原子比较设置操作。</p><p>与Lamport时间戳不同，线性寄存器的数字不会存在间隙，因此如果节点完成了消息4的发送，且接收了序列6的消息，那么它对消息6回复之前必须等待消息5。Lamport时间戳规则不是这样，这是区别全序关系广播与时间戳排序的关键。</p><p>如果不存在失效，实现线性寄存器不难，否则就等同于分布式共识算法。可以证明，<strong>线性化存储、全序广播、分布式共识三者是等价的</strong>。</p><h2 id="分布式事务与共识">分布式事务与共识</h2><h3 id="2PC">2PC</h3><p>两阶段提交（two-phase commit，2PC）是一种在多节点之间实现事务原子提交的算法，用来确保所有节点要么全部提交，要么全部中止。2PC在某些数据库内部使用，或者以XA事务形式（例如Java Transaction API）或SOAP Web服务WS-AtomicTransaction的形式提供给应用程序。</p><blockquote><p>2PC在分布式数据库中负责原子提交，2PL提供可串行化的隔离。</p></blockquote><p>2PC引入了一个角色：协调者（也称事务管理器），普通节点称为参与者。常见的协调者包括Narayana，JOTM，BTM或MSDTC。</p><p>2PC包括两个阶段：</p><ul><li>阶段1：协调者询问所有参与者是否准备好？如果都回答“是”则进入阶段2，否则中止。</li><li>阶段2：协调者向所有参与者发送提交请求。如果有参与者超时或失败，协调者会一直重试，直到成功为止。</li></ul><p>更详细的步骤：</p><ol><li>当应用程序启动一个分布式事务时，首先向协调者请求事务ID。该ID是全局唯一的。</li><li>应用程序在每个节点上执行单结点事务，并将全局唯一事务ID附加到事务上。如果这个阶段出现问题，协调者和其他参与者都可以安全中止。</li><li>当应用程序准备提交时，协调者向所有参与者发送准备请求。如果任何一个参与者失败或超时，协调者通知所有参与者放弃事务。</li><li>参与者收到准备请求后，确保在<strong>任何情况下</strong>都可以提交事务（包括系统崩溃，电源故障或磁盘空间不足），包括安全地将事务数据写入磁盘，并检查是否存在冲突或约束违规。</li><li>如果所有参与者都返回是，那么协调者将发送提交请求，并将决定写入磁盘的事务日志中。这个时刻称为<strong>提交点</strong>。</li><li>协调者发送提交请求。如果有参与者超时或失效，协调者将会一直重试，直到成功。</li></ol><p>类比结婚的例子，神父要问双方是否愿意嫁（娶）给对方，双方都回答“是”，神父才会宣布双方结为夫妻。并且，一旦说出“我愿意”就没有反悔的余地，即使之后马上晕倒了。</p><p>如果在参与者发送了准备好的回复后，协调者如果崩溃，参与者只能等待。因此2PC也被称为阻塞式原子提交协议。</p><h3 id="实践中的分布式事务">实践中的分布式事务</h3><p>分布式事务有严重的性能问题。例如，MySQL的分布式事务比单结点事务慢10倍以上。2PC性能下降的主要原因是事务日志以及额外的网络往返开销。</p><p>两类分布式事务：</p><ul><li>数据库内部：VoltDB和MySQL Cluster的NDB存储引擎就支持这样的内部分布式事务。</li><li>异构：存在两种或两种以上的不同的参与者实现技术。</li></ul><p>后者更具挑战。</p><h4 id="XA交易">XA交易</h4><p>X/Open XA（eXtended Architecture，XA）是异构环境下实施两阶段提交的一个工业标准，1991推出。目前许多传统关系数据库（包括PostgreSQL、MySQL、DB2、SQL Server和Oracle）和消息队列（包括ActiveMQ、HornetQ、MSMQ和IBM MQ）都支持XA。</p><p>XA不是一个网络协议，而是一个与事务协调者进行通信的C API。也有其他语言的绑定，比如JTA（Java Transaction API），JTA支持非常多的JDBC（Java Database Connectivity）和消息队列驱动（JMS）。</p><p>当参与者失效或协调者崩溃时，分布式事务陷入停顿，因为参与者有可能持有锁，比如数据库事务通常持有行级独占锁。可串行化隔离中两阶段锁的数据库还对曾经读取的行持有读-共享锁。参与者或协调者恢复可能也有意外发生，比如参与者重启也不会放弃锁（2PC正确实现要求），协调者丢失事务日志，这个时候就需要人工介入。</p><h3 id="支持容错的共识">支持容错的共识</h3><p>共识问题的形式化描述：一个或多个节点可以提议某些值，由共识算法来决定最终值。共识算法必须满足以下性质：</p><ul><li><p>协商一致性（Uniform agreement）</p><p>所有节点都接受相同的决议。</p></li><li><p>诚实性（Integrity）</p><p>所有节点不能反悔，即对一项提议不能有两次决定。</p></li><li><p>合法性（Validity）</p><p>如果决定了值v，则v一定是某个节点提议的。</p></li><li><p>可终止性（Termination）</p><p>节点如果不崩溃则最终一定可以达成决议。</p></li></ul><p>协商一致性和诚实性定义了共识的核心思想：<strong>决定一经做出，就不能改变</strong>。有效性排除了一些无意义的方案。可终止性引入了容错的思想。它强调一个共识算法要有所作为，不能空转。可终止性是一种活性，其他三个特性是安全性。</p><p>可终止性的前提是发生崩溃或不可用的节点必须小于半数节点。</p><p>大多数共识算法都假定不存在拜占庭式错误。但是研究表明，只要发生拜占庭式故障的节点少于三分之一，也可以达成共识。</p><h4 id="共识算法与全序广播">共识算法与全序广播</h4><p>最著名的共识算法有VSR、Paxos、Raft和ZAB。这些算法其实并没有直接使用上面的形式化模型（四大属性）。相反，它们定义了一系列值，然后采用全序关系广播算法，这样更加高效。</p><p>全序广播的要点是，消息按照相同的顺序到达所有节点，有且只有一次（不丢失，不重复）。相当于多轮共识：在每一轮，节点提出它们接下来想要发送的消息，然后决定下一个消息的全局顺序。</p><ul><li>由于协商一致性，所有节点决定以相同的顺序发送相同的消息（只是发送吗？）。</li><li>由于诚实性，消息不能重复。</li><li>由于合法性，消息不会被破坏，也不是凭空捏造。</li><li>由于可终止性，消息不会丢失。</li></ul><p>VSR、Raft和Zab都直接采取了全序关系广播，这比重复性的一轮共识只解决一个提议更高效。</p><h4 id="Epoch和Quorum">Epoch和Quorum</h4><p>问题是想要达成决议，必须先有主节点，想要主节点得让所有节点达成某种共识，看起来这是一个死循环。解决之道就是本节的内容。</p><p>协议定义了一个世代编号（epoch number），对应于Paxos中的ballot number，VSP中的view number，以及Raft中的term number，并保证在每个世代中，主节点是唯一的。</p><p>两轮投票：第一轮决定谁是主节点，第二轮对主节点的决议进行投票。关键一点，参与两轮的quorum（法定人数）必须有重叠。这样可以确保：没有发生更高epoch的主节点选举，当前的主节点地位没有改变，可以安全地就提议进行投票。</p><p>投票过程看起来很像2PC。区别在于，2PC协调者不是靠选举产生；容错共识算法只需要收集大部分节点的投票即可通过决议，而不像2PC收集全部的投票。</p><h3 id="成员与协调服务">成员与协调服务</h3><p>ZooKeeper和etcd被称为“分布式键值存储”或“协调与配置服务”。大多数情况下，可能不会直接使用这些服务，而是在中间件中间接的使用。功能包括：</p><ul><li>线性化原子操作：实现分布式锁。</li><li>操作全序：对每个操作都赋予一个事务ID（zxid）和版本号（cversion）。</li><li>故障检测：临时节点配合心跳检测。</li><li>更改通知：节点数据变化可以发送通知。</li></ul><p>适用的场景：</p><ul><li><p>节点任务分配</p><p>如果系统有多个实例，需要一个充当主节点。当主节点失效时，由其他节点来接管。或者分区动态增删，决定哪些分区分配给哪些节点。都可以使用ZK的临时节点和通知机制实现。</p></li><li><p>服务发现</p><p>例如，需要某项服务时，应该连接哪些ip等。传统上，通过服务名称获取IP地址使用DNS，它使用多层缓存实现高性能与高可用性，但是不满足线性化。</p></li><li><p>成员服务</p><p>用于确定哪些节点处于活动状态并属于集群的有效成员。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一致性保证&quot;&gt;一致性保证&lt;/h2&gt;
&lt;p&gt;分布式一致性与事务隔离级别有相似之处。但总体有着显著区别：事务隔离是为了处理并发执行事务时的各种临界条件，而分布式一致性则主要针对延迟和故障等问题来协调副本之间的状态。&lt;/p&gt;
&lt;h2 id=&quot;可线性化&quot;&gt;可线性化&lt;/h2
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第8章 分布式系统的挑战</title>
    <link href="https://naosense.github.io/2024/01/03/%E7%AC%AC8%E7%AB%A0%20%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8C%91%E6%88%98/"/>
    <id>https://naosense.github.io/2024/01/03/第8章 分布式系统的挑战/</id>
    <published>2024-01-03T18:14:10.000Z</published>
    <updated>2025-09-16T02:08:43.013Z</updated>
    
    <content type="html"><![CDATA[<p>对于大型分布式系统，部分组件失效几乎是一定的。</p><h2 id="不可靠的网络">不可靠的网络</h2><p>分布式系统故障或部分失效的一大原因。</p><h3 id="检测故障">检测故障</h3><p>检测故障没有什么万能的方法，如果能收到响应，通常使用各种状态码标识，另一些情况下通用的办法就是超时了。</p><h3 id="超时与无限期的延迟">超时与无限期的延迟</h3><p>超时成因：</p><ul><li>负载过重，排队。</li><li>CPU繁忙。</li><li>虚拟机环境切换。</li><li>TCP流量控制（也称拥塞消除，或背压）。</li></ul><blockquote><p>TCP与UDP</p><p>UDP不支持流量控制也不支持重传丢失的数据包，速度较快。如果延迟或丢失的数据价值不大，UDP是一个不错的选择。比如IP电话，应用程序会采用静音填充丢失的位置（出现短暂声音中断）。</p></blockquote><p>超时设置长了或短了都不好。更好的方法是自动调整，比如Phi Accrual故障检测器，已经在Akka和Cassandra中使用。TCP重传也采用了类似的机制。</p><h3 id="同步与异步网络">同步与异步网络</h3><p>固定电话网在打电话时会动态建立一条电路：一个固定的、带宽有保证的通信链路，这种网络本质是同步的，不会受到排队的影响。由于没有排队，网络最大的端到端延迟是固定的。我们称之为<strong>有界延迟</strong>。</p><p>究其根本是目地不同，电话网线路持续时间短，要求及时性，而以太网追求资源的最大化利用。有了这个目的以太网才采用了分组交换协议，这样可以最大化的利用带宽：带宽小的时候我就传少点，带宽大的时候我就传多点。</p><blockquote><p>简言之，网络中可变延迟并不是一种自然规律，只是成本与收益相互博奕的结果。</p></blockquote><h2 id="不可靠的时钟">不可靠的时钟</h2><p>计算机内部至少有两种时钟：<strong>墙上时钟</strong>（或称钟表时间）和<strong>单调时钟</strong>。</p><p>墙上时钟返回当前日期与时间。例如，Linux的<code>clock_gettime(CLOCK_REALTIME)</code>和Java中的<code>System.currentTimeMillis()</code>会返回子1970年1月1日（UTC）以来的秒数和毫秒数，不含闰秒。墙上时钟在和NTP同步的时候，可能会跳回先前的时间点，不适合测量时间间隔。</p><p>单调时钟如Linux的<code>clock_gettime(CLOCK_MONOTONIC)</code>和Java中的<code>System.nanoTime()</code>。单调时钟保证总是向前。</p><p>如果一些服务依赖时间戳，比如LWW系统，时间如果不准将会造成严重的后果。例如下面的例子，错误的时间戳导致客户端B的更新丢失。</p><p><img src="bad_timestamp.jpeg" alt="bad timestamp"></p><p>某些软件如果在指定时间内无法相应则会导致严重后果，比如飞机、火箭、机器人、汽车和其他需要对输入传感器快速做出响应的组件等。对于这些系统，软件有一个必须做出响应的上限：如果无法满足，会导致系统级故障，这就是所谓的<strong>硬实时系统</strong>。</p><blockquote><p>在嵌入式系统中，实时通常意味着系统经过了精心设计和测试，以满足各种情况下执行时间约束。Web中的实时则通常是指一种持续的流式处理方式，并没有强的时间约束。</p></blockquote><h2 id="知识，真相与谎言">知识，真相与谎言</h2><h3 id="真相由多数决定">真相由多数决定</h3><p>在很多情况下，系统范围内只能有一个实例。例如：</p><ul><li>只允许一个节点作为数据库分区的主节点，防止出现脑裂。</li><li>只允许一个事务或客户端持有特定资源的锁，以防止同时写入从而导致数据破坏。</li><li>只允许一个用户来使用特定的用户名，从而确保用户名可以唯一标识用户。</li></ul><p>在分布式系统中，某个节点自认为它是“唯一的那个”，但不一定获得了系统法定票数的统一！例如下面由于不正确加锁而导致数据破坏的例子。</p><p><img src="fencing.jpeg" alt="fencing"></p><p>一种简单的解决办法是使用<strong>栅栏</strong>（fencing）：每次锁服务在授予锁或租约时，还会同时返回一个fencing令牌，该令牌每授予一次都会递增。然后，要求客户端每次向存储系统发送写请求时，都必须包含所持有的fencing令牌。</p><p>使用ZooKeeper作为锁服务时，事务标识zxid或节点版本cversion都可以充当令牌。</p><h3 id="拜占庭故障">拜占庭故障</h3><p>fencing令牌可以检测并阻止哪些无意的误操作。如果节点存在“撒谎”的情况（即故意发送错误或破坏性的响应），这种行为称为<strong>拜占庭故障</strong>，在这样的不信任环境钟需要达成共识的问题也被称为<strong>拜占庭将军问题</strong>。</p><blockquote><p>拜占庭将军问题指有n位将军需要达成共识，并且其中存在一些叛徒试图阻挠达成共识。大多数将军都是忠诚的，而且大家事先并不知道叛徒是谁。</p></blockquote><p>如果系统中部分节点故障，甚至不遵从协议，或者恶意估计、干扰网络，但仍可运行，那么我们称之为<strong>拜占庭式容错系统</strong>。这些担忧在某些特定场景是合理的。例如：</p><ul><li>航空航天领域，计算机内存或CPU寄存器受辐射影响，导致以不可预知的方式响应其他节点。</li><li>在多个参与者的系统中，某些参与者可能会作弊或者欺骗他人。比如比特币或其他区块链一样的点对点网络就是让互不信任的双方就某项交易达成一致，且不依赖集中的机制。</li></ul><p>尽管我们假设节点通常是诚实的，但有必要防范一些不那么恶意的“谎言”。例如：</p><ul><li>由于硬件问题或操作系统、驱动程序、路由器等方面的错误，导致网络数据包又是出现损坏。可以借助校验和来校验和发现这类问题。</li><li>对公众开放的应用必须仔细检查用户的所有输入。例如输入值是否在合理范围、有没有不合理的字符。</li><li>NTP客户端最好配置多个时间服务器。</li></ul><h3 id="理论系统模型与现实">理论系统模型与现实</h3><p>关于计时，有三种常见的系统模型：</p><ul><li>同步模型。假定有上界的网络延迟，有上界的进程暂停和有上界的时钟误差。</li><li>部分同步模型。系统在大多数情况下像一个同步系统一样运行，但有时候会超出上界。这是一个比较现实的模型。</li><li>异步模型。对时机没有任何假设，甚至里面根本没有时钟。</li></ul><p>节点失效，也有三种模型：</p><ul><li>崩溃-终止模型。一个节点只能以一种方式发生故障，即遭遇系统崩溃。</li><li>崩溃-恢复模型。节点可能会在任何时候崩溃，且可能会在一段（未知的）时间之后恢复并再次响应。</li><li>拜占庭（任意）失效模型。节点可能发生任何事情，包括试图作弊和欺骗其他节点。</li></ul><p>安全性通常可以理解为“没有发生意外”，活性则类似“预期的事情最终一定会发生”。比如，唯一性和单调递增属于安全性，可用性和一致性属于活性。区分安全性和活性的一个好处是可以帮助简化处理一些具有挑战性的系统模型。安全性是必须要满足的，活性的满足则需要一定的必要条件。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对于大型分布式系统，部分组件失效几乎是一定的。&lt;/p&gt;
&lt;h2 id=&quot;不可靠的网络&quot;&gt;不可靠的网络&lt;/h2&gt;
&lt;p&gt;分布式系统故障或部分失效的一大原因。&lt;/p&gt;
&lt;h3 id=&quot;检测故障&quot;&gt;检测故障&lt;/h3&gt;
&lt;p&gt;检测故障没有什么万能的方法，如果能收到响应，通常使用各种
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>元旦西安跨年行</title>
    <link href="https://naosense.github.io/2024/01/03/%E5%85%83%E6%97%A6%E8%A5%BF%E5%AE%89%E8%B7%A8%E5%B9%B4%E8%A1%8C/"/>
    <id>https://naosense.github.io/2024/01/03/元旦西安跨年行/</id>
    <published>2024-01-03T09:16:44.000Z</published>
    <updated>2025-09-16T02:08:42.964Z</updated>
    
    <content type="html"><![CDATA[<p>29号请了一天假，1号回来的，总共玩了三天。</p><h2 id="第一天-城墙-鼓楼-回民街-洒金桥-钟楼">第一天 城墙-鼓楼-回民街-洒金桥-钟楼</h2><p>29号上午12点到的，去酒店旁边的澄城水盆羊肉吃了个水盆羊肉套餐，也许是饿了，味道是真不错，最后连汤都喝干净了。</p><p>稍微休整了下，我们就奔城墙而去了。查了下距离，离得不远，也就一公里多，我们就走着过去了。</p><p>从永宁门买的票，到长乐门下来的，走了整个城墙的小1/4圈。顺便提一句，碑林也在永宁门附近，不过我们没去。没骑自行车是因为有小孩，自行车只有单人和双人。当天人不多，或许是还没放假。城墙的一半被围起来了，看着里面在扎花灯。</p><p><img src="%E5%9F%8E%E5%A2%99.jpeg" alt="城墙"></p><p>从长乐门下来后，我们一路又走到了回民街。回民街其实相当于北京的南锣鼓巷，就是一条小吃街，只不过比南锣鼓巷要大。我们大概是晚上7点到的回民街，人也不多。尝了尝桂花糕和烤串，烤串和北京回民烤串差不多，都是外面裹一层东西再烤。桂花糕我觉得桂花太少了，几乎没有桂花味。其他小吃如肉夹馍、凉皮、泡馍之类没啥欲望，在北京或多或少都吃过。</p><p><img src="%E5%9B%9E%E6%B0%91%E8%A1%97.jpeg" alt="回民街"></p><p>看网上说洒金桥是当地人比较喜欢去的小吃街，我们一路又转到洒金桥。离回民街不远，大概一公里。在这吃到了在家尝试过的粉蒸牛肉。和自己做的相比，他的味道花椒茴香味比较浓，面比较散，不像自己做的面是黏的 但是他的肉比较硬。总之，吃起来并没有网上视频说的那么惊艳。</p><p>最后从洒金桥又走到了钟楼。本来想打车的，但是所到之处都是一些小街小巷，怕出租车不好进。在这扫了一个共享单车，推着孩子一路走到了钟楼。钟楼算是西安的标志性建筑了。有好多小姐姐身着汉服在这拍照，搔首弄姿，好不热闹。</p><p><img src="%E9%92%9F%E6%A5%BC.jpeg" alt="钟楼"></p><p>回到酒店一看走了27000多步，这一天可把大家累坏了，sign。其实这一天的大部分路都可以打车，只是这样会少很多体验感，这也算是一种取舍吧。</p><h2 id="第二天-大雁塔-大唐不夜城">第二天 大雁塔-大唐不夜城</h2><p>不能免俗，我们也去租了身汉服，地点就在钟楼附近的汉服城。下面是一个一个的小隔间，各种各样的汉服应有尽有，价格100-300一天不等。</p><p>化好妆吃了午饭会酒店休息了一会。我在马蜂窝查到的信息大雁塔喷泉是4点6点8点各有一场，4点天太亮没效果，就奔6点这场了。到达的大雁塔4点多，逛了一阵就快6点了。原本想等着6点看喷泉，谁知保安说7点才有，想着先去大唐不夜城转转，等会再回来看。这两个地点离得很近，没想到一转就转不回来了，因为大唐不夜城太大了，再加上晚上人开始多了，实现单向管制了，想回来必须得绕一大圈。</p><img width="600" alt="大雁塔" src="大雁塔.jpeg"><p>大唐不夜城太大了，里面还有各种表演，想一次转完太难了。算下来，我们只看了一个表演：贞观之治，吃了若干小吃，没有看到著名的不倒翁小姐姐。不过，既然是旅游，不妨随性一点，所谓“乘兴而来，兴尽而归”，氛围感受到了就行了。</p><p><img src="%E5%A4%A7%E5%94%90%E4%B8%8D%E5%A4%9C%E5%9F%8E.jpeg" alt="大唐不夜城"></p><h2 id="第三天-华清池-兵马俑">第三天 华清池-兵马俑</h2><p>今天有个大坑，大家可要看仔细了。</p><p>差不多十年前我去过一次，当时自己一个人去的，坐的公交车，没有请讲解。和大多数景点一样，看了啥印象都没有。所以，这次想着报个一日团，一来车接车送，二来有个讲解。两大人一小孩总共550倒也不贵，没成想，上了车就被那导游花言巧语把我骗，把我骗哎呀啊。</p><p>事情是这样的，上车暖场后，导游就说起来兵马俑的面积之大，文化之深，什么相当于故宫的多少倍，分为东西两区，西区是活的兵马俑，东区是死的兵马俑，活的看懂了才能看懂死的，活的死的都要看云云（事后才知道所谓西区就是私人开设的小型体验馆，东区才是真正的兵马俑一二三号坑）。</p><p>接下来就是图穷匕见的时刻了，大家记住两个关键字：铁鹰锐士和地宫，这两个项目加起来每个人要补278。所谓铁鹰锐士就是一个小型体验馆，地宫就是一个十分钟的VR。其实这时候我已经知道这是套路了，但是一来我被导游在车上绘声绘色的描述整好奇了，二来带着孩子想多体验点东西，三来她说如果不看活的兵马俑，死的就没有讲解了，所以就报了。</p><p>平心而论，这两个项目合起来能值100-120，但是收费278属实是贵了。事后发现，不报这两个项目完全没问题，兵马俑讲解根本就不是导游，而是博物馆内部工作人员，不存在没有讲解的情况，导游在游览兵马俑景区的作用只是引导你去各种地点，参与度很低。不报这两个项目，只需要按时去参观兵马俑一二三号坑就行。导游就是连哄带骗带你入坑。不想被骗的话只需收起好奇心，态度坚决点拒绝就行。</p><p>抛开这个插曲，这个一日团还不错，车接车送，华清池和兵马俑两个景点门票和讲解，一顿午餐。华清池是导游讲解的，讲的也不错。兵马俑的讲解是博物馆内部人员，也非常不错。只是当天人太多了，一号坑那里简直像赶集一样，走路只能向前挪动，到了后面的二号坑三号坑就好多了。多亏有了讲解，比我那次单枪匹马游览强多了。</p><p>回程的路上，不出意外，导游又开始套路卖特产了哈哈。不过都是些小打小闹，就不细说了。后来我自己去特产店买的，差的不多。</p><p>总之，这趟西安之行整体感觉还不错，吃的住的都没遇到坑，景点也各有特色。相比于北京故宫的金碧辉煌，我更喜欢西安古建的古朴大气。和十年前一样，游览的这三天，西安的雾霾没断过，不知是不是冬天取暖导致的。</p><p>顺便提一句几块比较大的费用吧，北京到西安来回路费2600左右，住宿三天1000左右，景点门票+旅游团1200左右，总共5000左右。住宿建议住在钟楼附近，钟楼应该是西安的中心，这个地方离哪里都不远。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;29号请了一天假，1号回来的，总共玩了三天。&lt;/p&gt;
&lt;h2 id=&quot;第一天-城墙-鼓楼-回民街-洒金桥-钟楼&quot;&gt;第一天 城墙-鼓楼-回民街-洒金桥-钟楼&lt;/h2&gt;
&lt;p&gt;29号上午12点到的，去酒店旁边的澄城水盆羊肉吃了个水盆羊肉套餐，也许是饿了，味道是真不错，最后连汤都
      
    
    </summary>
    
    
      <category term="西安" scheme="https://naosense.github.io/tags/%E8%A5%BF%E5%AE%89/"/>
    
      <category term="旅游" scheme="https://naosense.github.io/tags/%E6%97%85%E6%B8%B8/"/>
    
      <category term="兵马俑" scheme="https://naosense.github.io/tags/%E5%85%B5%E9%A9%AC%E4%BF%91/"/>
    
      <category term="回民街" scheme="https://naosense.github.io/tags/%E5%9B%9E%E6%B0%91%E8%A1%97/"/>
    
      <category term="华清池" scheme="https://naosense.github.io/tags/%E5%8D%8E%E6%B8%85%E6%B1%A0/"/>
    
  </entry>
  
  <entry>
    <title>2023，程序员佛系减肥在路上</title>
    <link href="https://naosense.github.io/2023/12/27/2023%EF%BC%8C%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BD%9B%E7%B3%BB%E5%87%8F%E8%82%A5%E5%9C%A8%E8%B7%AF%E4%B8%8A/"/>
    <id>https://naosense.github.io/2023/12/27/2023，程序员佛系减肥在路上/</id>
    <published>2023-12-27T19:40:17.000Z</published>
    <updated>2025-09-16T02:08:42.938Z</updated>
    
    <content type="html"><![CDATA[<h2 id="最初的动机">最初的动机</h2><p>其实一直对体重都没怎么注意过，男的嘛，对自己身材没那么在意，只是每年买的裤子到下年就不能穿了，浪费了不少钱（笑）。</p><p>直到上年年底体检，体检报告上有一项“超重，脂肪肝（中）”，着实还是给了我一点小小的震撼。以往的体检顶多是“甘油三酯高，转氨酶高”，现在好家伙都发展成中度脂肪肝了。我当时BMI已经超过25，体重一度逼近160。</p><p>为了“为祖国健康工作五十年”的宏伟目标，我决心要把这个肥给减下去。</p><h2 id="取得的成果">取得的成果</h2><p>今年一年跑步历程。</p><img width="1000" alt="running 2023" src="running_2023.jpeg"><p>今年一年体重变化。</p><img width="1000" alt="weight 2023" src="weight_2023.jpeg"><p>之前异常的指标去年今年对比。</p><table><thead><tr><th style="text-align:center">指标</th><th style="text-align:center">2022</th><th style="text-align:center">2023</th><th style="text-align:center">参考值</th></tr></thead><tbody><tr><td style="text-align:center">体重</td><td style="text-align:center">78.5</td><td style="text-align:center">71.7</td><td style="text-align:center">–</td></tr><tr><td style="text-align:center">甘油三脂</td><td style="text-align:center">4.24</td><td style="text-align:center">1.64</td><td style="text-align:center">0.45~1.70</td></tr><tr><td style="text-align:center">丙氨酸氨基转移酶</td><td style="text-align:center">52</td><td style="text-align:center">29</td><td style="text-align:center">0~50</td></tr><tr><td style="text-align:center">γ-谷氨酰转移酶</td><td style="text-align:center">78</td><td style="text-align:center">35</td><td style="text-align:center">10~60</td></tr></tbody></table><p>算下来，瘦了没几斤，但是效果非常显著。就连连续几年一直居高不下的甘油三酯和两个转氨酶也头一次正常了，这真的意想不到。</p><p>虽说这次跑步的初衷是减肥，但收获不止于此，还收获了一个附属品——恒心，所谓“一事有恒，万事渐振”。朋友都说没之前臃肿了，人的精神状态也变好了。</p><h2 id="采取的行动">采取的行动</h2><p>我比较懒散，因此也没制定计划。因为根据以往的经验，计划对我来说非但不会让我坚持下去可能还有反作用。每天想跑就跑，实在哪天不想跑，就不跑。</p><p>其次呢，就是晚饭不吃正餐，吃点水果。但是呢，哪天如果实在饿，也吃晚饭。也不计算卡路里摄入量这些东西，主打就是一个随性和佛系。</p><p>有人说，不吃晚饭我饿呀，饿的睡不着。你别说，我第一天没吃晚饭确实是这样子的。打工人中午这顿饭离睡觉太长了，晚上一点不吃真不行，因此我将其调整为不吃正餐，吃点水果啥的。</p><h2 id="如何坚持">如何坚持</h2><p>詹姆斯.克利尔在《掌握习惯》中介绍了习惯的四大定律：</p><ul><li>让习惯显而易见。</li><li>让习惯有吸引力。</li><li>让习惯简便易行。</li><li>让习惯令人愉悦。</li></ul><p>我上面说不制定计划，不计算卡路里，就是为了让习惯显而易见和简便易行，跑步就是简单的迈开腿跑就是了，没有距离快慢的要求。</p><p>那怎么让跑步变得有吸引力？合理利用自己的虚荣心是一种方式。比如使用一些关注长期主义的软件如<a href="https://github.com/naosense/miles">miles</a>、<a href="https://github.com/yihong0618/running_page">running_page</a>记录自己跑步的历程。</p><img width="768" alt="miles" src="miles.jpeg"><img width="768" alt="running page" src="running_page.jpeg"><p>还可以给自己的跑步赋予更多的意义。比如将省下的饭钱捐出一些，来达到令人愉悦的目的，赠人玫瑰，手留余香嘛。</p><img width="200" alt="donate" src="donate.jpeg"><p>还有一招，我称之为“减量不减次”：如果哪天不想跑，不要完全不跑，而是适当的减少跑步的距离。比如你平常跑五公里，那现在就跑三公里，甚至一公里，这样可以提高放弃的门槛。你明天状态好了，还可以跑回来，避免轻易地放弃，否则很容易有“反正昨天没跑，计划已经断了，没必要再坚持了”的想法。类似于股票跌的时候不要一下子全卖掉，而是逐次抛售，万一明天涨回来你还可以继续持有。</p><p>不过话说回来，如果状态实在不好，也千万不要强迫自己。比如有时候上一天班感觉很累，那就停一天，没啥大不了。</p><p>对了，如果能够找个人结伴跑步也会有助于坚持下去。我之前在小区一个人跑，跑不多远就累了，后来和一个同事一起跑，跑得又快又轻松。</p><h2 id="去哪里跑">去哪里跑</h2><p>我觉得作为打工人能选择的跑步地点按优先级有以下几种：</p><ol><li>有跑道的公园。</li><li>小区道路。</li><li>人行辅路。</li><li>跑步机。</li></ol><p>第1种可遇不可求，如果家门口或者办公地点附近有这种地方，不用说，这是首选。如果离得太远，特意过去跑步，就有点得不偿失。</p><p>第2种属于内部道路，比较安全，但是通常来说比较短，跑起来容易乏味。还有一点，小区里楼比较多，路短，根据我个人经历，GPS跟踪不太准。</p><p>第3种属于外部路，人车混杂，如果晚上跑得话，视野不好，路况不好的话容易崴脚。而且晚上这种道路上，遛狗的，送外卖的，电动车，自行车，狗绳，你都得花精力躲避，搞不好还有危险。我试着跑了一段时间，就放弃了。</p><p>跑步机的话，一般我冬天才会选择。密闭空间，跑起来比较乏味，空气也不好。</p><p>刚开始，我就在小区跑，后来发现上班的地方附近正好有个临河公园，有健身跑道，我就去那了。</p><h2 id="早上还是晚上">早上还是晚上</h2><p>作为打工人，生活在城市中，早上跑的好处是人少，视野开阔，空气好（一说早上空气并不好）；晚上跑身体机能已经完全预热，时间也比较充裕，好安排。</p><p>我现在选择的是晚上。也试过早上，给我的感觉是跑起来心跳很快，就好像身体还没完全打开，就改成晚上了。</p><p>不过大家大可不必在这个事上纠结，所谓选择困难症往往是因为“想的多，做的少”。犹豫不决的时候试下就知道，没有多少成本。</p><h2 id="没时间怎么办">没时间怎么办</h2><p>其实跑步花不了多长时间。按六分钟配速，如果跑两公里的话，跑步洗澡半小时也够了。我是不信一个人一天挤不出来半小时时间的，一集电视剧都不止半小时！</p><p>如果实在找不出成块的时间，还可以碎片式跑步，比如从家到地铁的这段路上可以利用起来。</p><h2 id="每逢过节胖三斤">每逢过节胖三斤</h2><p>非常有道理啊。大家可以看上面的体重波动，五一、十一这些假日确实会反弹。究其原因，我个人的情况应该是过节没法正常节食，好不容易放假回趟家，父母怎么能允许你节食呢？一方面吃的多了，另一方面也不规律地跑步了，体重自然就上来了（笑）。</p><p>不过问题不大，一旦假期结束，重新跑起来，体重很快就会恢复正常。</p><p>写在最后，就像丹尼尔.利伯曼在《锻炼》中建议的那样：</p><blockquote><p>为了自己的身体，动起来，为了自己的脑子，动起来。</p><p>对于大部分人，每周150分钟的中强度锻炼即可，多了没坏处，但也没多大用。大多数时间进行有氧运动，但也别忘了加入一些力量训练。</p></blockquote><p>力量训练我也是从简，就是做做俯卧撑。</p><p>总之一句话，开跑有益，无论是在生理上还是心理上！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;最初的动机&quot;&gt;最初的动机&lt;/h2&gt;
&lt;p&gt;其实一直对体重都没怎么注意过，男的嘛，对自己身材没那么在意，只是每年买的裤子到下年就不能穿了，浪费了不少钱（笑）。&lt;/p&gt;
&lt;p&gt;直到上年年底体检，体检报告上有一项“超重，脂肪肝（中）”，着实还是给了我一点小小的震撼。以往
      
    
    </summary>
    
    
      <category term="年度总结" scheme="https://naosense.github.io/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
      <category term="跑步" scheme="https://naosense.github.io/tags/%E8%B7%91%E6%AD%A5/"/>
    
      <category term="减肥" scheme="https://naosense.github.io/tags/%E5%87%8F%E8%82%A5/"/>
    
  </entry>
  
  <entry>
    <title>第7章 事务</title>
    <link href="https://naosense.github.io/2023/12/25/%E7%AC%AC7%E7%AB%A0%20%E4%BA%8B%E5%8A%A1/"/>
    <id>https://naosense.github.io/2023/12/25/第7章 事务/</id>
    <published>2023-12-25T11:02:15.000Z</published>
    <updated>2025-09-16T02:08:43.007Z</updated>
    
    <content type="html"><![CDATA[<h2 id="深入理解事务">深入理解事务</h2><p>事务将多个读写操作捆绑成一个逻辑整体，要么都成功，要么都失败。</p><h3 id="ACID">ACID</h3><p>原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。</p><p>BASE</p><p>基本可用性(Basically Available)，软状态（Soft state）和最终一致性（Eventual consistency）。</p><blockquote><p>各家数据库所实现的ACID并不尽相同，更像是一个市场营销用语。BASE是另一套标准，同样模棱两可，唯一可以确定的是“它不是ACID”。</p></blockquote><h4 id="原子性">原子性</h4><p>要么成功，要么失败，不能部分成功部分失败。</p><p>在ACID的语境中，指的是出错时终止事务，并将部分完成的写入丢弃。</p><h4 id="一致性">一致性</h4><p>一致性是指对数据有特定的预期状态（满足特定的约束），比如银行贷款和借款余额保持相等。</p><p>一致性是<strong>应用层提供的属性</strong>，其他三个是数据库应提供的属性。</p><h4 id="隔离性">隔离性</h4><p>并发执行的多个事务互相隔离，不能交叉。多个事务执行的效果和串行执行一样，但内部实现不要求一定串行执行。</p><p>下面的例子中，用户1和用户2分别更新同一个对象，最终结果本来应该为44，现在是43。由于没有隔离，导致用户1的更新丢失。</p><p><img src="race_condition.jpeg" alt="race condition"></p><h4 id="持久性">持久性</h4><p>提供一个安全可靠的地方存储数据而不用担心数据丢失。在计算机语境下常常指写入磁盘。</p><h3 id="单对象与多对象事务操作">单对象与多对象事务操作</h3><p>单对象事务，比如向数据库写入20KB的JSON文档，多对象事务，比如外键的更新，二级索引的更新等。</p><h2 id="弱隔离级别">弱隔离级别</h2><p>所谓弱隔离级别在这里的意思是非串行化。</p><blockquote><p>MySQL等数据库的四种隔离级别：读未提交，读提交，可重复读，串行化。</p></blockquote><h3 id="读-提交">读-提交</h3><p>读-提交是最基本的隔离级别，它指提供如下两个保证：</p><ol><li>读数据时，只能看到已成功提交的数据（防止“脏读”）。</li><li>写数据时，只会覆盖已成功提交的数据（防止“脏写”）。</li></ol><p>读-提交非常流行，它是Oracle 11g、PostgreSQL、SQL Server 2012、MemSQL以及许多其他数据库的默认配置。</p><p>脏写一般通过行级锁来实现，当事务想修改某个对象，它必须先获取该对象的锁。</p><p>脏读的话，理论上也可以这么做，但是这样做性能太差。因此，实际一般都是维护旧值和当前事务设置的新值两个版本。在事务提交前，读取旧版本，事务提交后，才读取新版本。</p><h3 id="快照级别隔离与可重复读">快照级别隔离与可重复读</h3><p>读-提交有不可重复读（nonrepeatable read）或读倾斜（read skew）<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>的问题。</p><p>转帐者从账户1转帐100块到账户2，初始时两个账户都是500块钱，由于发生了脏读，Alice看到了转帐事务的中间状态，她看到账户1是500块，账户2是400块，少了100块。</p><p><img src="read_skew.jpeg" alt="read skew"></p><p>这种问题，在一些场景是不可接受的：</p><ul><li>备份场景：备份里可能含有新旧两个版本的数据，如果从这样的备份恢复，最终就会导致永久的不一致。</li><li>分析查询与完整性检查：这种查询可能会扫描大半个数据库，亦或定期的数据完整性检查。如果这些查询在不同的时间点观察数据库，可能会返回无意义的结果。</li></ul><p>快照级别隔离是最常见的解决方法。它的想法是，每个事务都从数据库的一致性快照中读取，事务一开始锁看到的是最近提交的数据，即使数据随后被其他事务修改，但保证每个事务都只能看到特定时间点的旧数据。</p><p>基本上常见数据库都实现了这种隔离级别。</p><p>采用一种类似于读-提交中防止脏读但更通用的方案，保留对象的多个不同的提交版本，这种技术称为<strong>多版本并发控制</strong>（Multi-Version Concurrency Control，MVCC）。</p><p>既然是更通用的方案，因此在实现读-提交时，干脆也用MVCC，通过维护对象的两个版本就够了：一个已提交的旧版本和尚未提交的新版本。典型做法是，在读-提交级别下，对每一个不同的查询创建一个快照；在快照隔离级别下，则使用一个快照来运行整个事务。</p><blockquote><p>前面不是说两个版本就够了，为啥后面又说一个查询一个快照呢？</p><p>我个人理解，在读-提交级别下，事务中每个查询都创建一个快照是为了反映最新的提交。虽然是每次查询都创建一个新的快照，但是新的快照是覆盖旧的快照得来的，在每一个时刻，系统始终只有两个版本。因此前文说只需要两个版本，后面又说一个查询一个快照，不矛盾。</p></blockquote><p><img src="mvcc.jpeg" alt="mvcc"></p><h4 id="一致性快照的可见性规则">一致性快照的可见性规则</h4><ol><li>每笔事务开始时，列出所有当时尚未提交的其他事务，忽略这些事务的部分写入。</li><li>所有中止事务所做的修改全部不可见。</li><li>较晚事务所做的修改不可见。</li><li>除此之外，其他所有写入都可见。</li></ol><p>换句话说，仅当以下两个条件都成立，则改数据对象对事务可见：</p><ul><li>事务开始的时刻，创建该对象的事务已经完成了提交。</li><li>对象没有被标记删除，或者即使标记了，但删除事务在事务开始时还没有完成提交。</li></ul><p>一句话，就是<strong>一个事务只能看到它开始之前已经提交的事务所做的修改。</strong></p><h4 id="索引与快照级别隔离">索引与快照级别隔离</h4><p>多版本数据库如何支持索引：</p><ol><li>将索引指向对象的所有版本，然后想办法过滤对当前事务不可见的那些版本。典型如PostgreSQL。</li><li>采用追加式的BTree，更新时，不是原地修改，而是创建一个修改副本，拷贝必要内容。</li></ol><h3 id="防止更新丢失">防止更新丢失</h3><p>读提交和快照隔离没有解决两个写事务并发，而脏写只是写并发的一个特例。最著名就是更新丢失问题，比如：</p><ul><li>read-modify-write场景。</li><li>对复杂对象的一部分内容执行修改，再写回。</li><li>两个用户同时编辑wiki页面，覆盖现有内容。</li></ul><p>解决方案：</p><ul><li>原子写操作。类似于Java语言中的CAS操作，比如下面指令<pre><code class="language-sql">UPDATE counters SET value = value + 1 WHERE key = 'foo';</code></pre>从实现上一是加独占锁，二是强制在单线程上运行。</li><li>显式加锁。如果数据库不支持原子操作，可以显式锁定待更新的对象。<pre><code class="language-sql">BEGIN TRANSACTION;SELECT * FROM figuresWHERE name = 'robot' AND game_id = 222FOR UPDATE;-- Check whether move is valid, then update the-- position of the piece that was returned by the previous SELECT.UPDATE figures SET position C4 WHERE id = 1234;COMMIT;</code></pre><code>FOR UPDATE</code>对返回的所有结果行加锁。</li><li>自动检测更新丢失。属于一种乐观锁机制，也就是先并发执行，如果事务管理器检测到了更新丢失的风险，回退到安全的“读-修改-写回”方式。可惜的是并不是所有的数据库都实现了这种机制。</li></ul><h3 id="写倾斜与幻读">写倾斜与幻读</h3><p>一个例子，正在开发一个程序帮助医生管理轮班。通常，会安排多个医生值班，医生也可以调整班次，但得确保至少一位医生值班。</p><p>现在Alice和Bob两位值班医生，碰巧都感觉身体不适，在同一时刻点击调班按钮。在快照隔离级别，前置检查都返回两位医生，所以两个事务都进入下一阶段，最终导致没有任何医生值班。</p><p><img src="write_skew.jpeg" alt="write skew"></p><p>这种异常称之为<strong>写倾斜</strong>。它不是脏写，也不是更新丢失。可以将其看作一种更广义的更新丢失问题。即两个事务先读取相同的一组对象，更新其中的一部分：不同的事务可能更新不同的对象，则可能发生写倾斜；如果更新同一个对象，则可能发生脏写或更新丢失。</p><p>更多例子：</p><ul><li>会议系统，多人抢占一个会议室。</li><li>多人游戏。</li><li>声明一个用户名，保证唯一性。</li><li>防止双重开支，避免同时插入两个开支项目。</li></ul><p>在一个事务中的写入改变了另一个事务查询结果的现象，称为幻读。快照级别的隔离可以避免只读查询时的幻读，但是无法解决写倾斜。</p><h2 id="串行化">串行化</h2><p>写倾斜的解决方法是串行化。即事务可以并行执行，但是执行结果必须和串行执行相同。</p><h3 id="实际串行执行">实际串行执行</h3><p>使用存储过程单线程运行。但有一下限制：</p><ul><li>事务必须简短而高效，否则一个慢事务会影响所有其他事务的性能（和异步化类似）。</li><li>仅限于活动数据集完全可以加载到内存的场景。访问磁盘会严重拖累性能。</li><li>写入吞吐量必须足够低，才能在单个CPU上处理；否则就需要分区，最好没有跨分区事务。</li><li>跨分区事务虽然也可以支持，但是占比必须很小。</li></ul><h3 id="两阶段加锁">两阶段加锁</h3><p>快照隔离级别“读写互不干扰”，2PL读写是互斥的。它的想法是：</p><ul><li>如果事务A已经读取了某个对象，此时事务B想写入该对象，那么B必须等到A提交或中止才能继续。</li><li>如果事务A已经修改了对象，事务B想要读取该对象，则B必须等到A提交或中止才能继续。</li></ul><blockquote><p>两阶段加锁（2PL）听起来和两阶段提交（2-phrase commit，2PC）很相近，但它们是完全不同的东西。</p></blockquote><p>目前2PL已经用在了MySQL（InnoDB）和SQL Server的“可串行化隔离”，以及DB2中的“可重复读隔离”。</p><p>实现方案为为每个对象都维护一个<strong>读写锁</strong>来隔离读写操作。即锁可以处于共享模式或独占模式，运行机制如下：</p><ul><li>如果事务要读取对象，必须获得共享锁。多个事务可以同时获得一个共享锁，但是如果某个事务已经获得了独占锁，则所有事务必须等待。</li><li>如果事务要修改对象，必须以独占模式获得锁。不允许多个事务同时持有该锁（包括共享或独占模式）。</li><li>如果事务首先读取对象，后面想尝试写入，则需要将共享锁升级为独占锁。</li><li>事务获得锁之后，一直持有锁直到事务结束。这也是“两阶段”的来由，在第一阶段即事务执行之前获取锁，第二阶段即事务结束时释放锁。</li></ul><p>也就是只有共享-共享可以共存，独占-独占，共享-独占都是互斥的。</p><p>锁的实现：</p><ul><li>谓词锁。也就是符合某种搜索条件的所有查询对象共同持有一个锁。</li><li>索引区间锁。谓词锁性能较差，索引区间锁是谓词锁的简化版，实现原理是将保护的对象扩大化，也就是锁粗化。比如谓词条件是：房间123，时间段是中午到下午1点，索引区间锁即只保护房间123的所有时间段。如果没有合适的索引可以施加区间锁，会回退到整条加共享锁。</li></ul><p>2PL自1970年提出后不被广泛接纳的原因是相比弱隔离级别吞吐量和查询响应下降的非常多。</p><h3 id="可串行化的快照隔离">可串行化的快照隔离</h3><p>SSI（Serializable Snapshot Isolation），在2008年被首次提出，提供了完整的串行化保证，性能比快照隔离损失很小。</p><p>目前用在了PostgreSQL9.1之后的可串行化隔离和分布式数据库如FoundationDB。</p><p>它的想法是让事务并发执行，寄希望于相安无事，当事务提交时，数据库检查是否确实发生了冲突，如果是的话，中止事务并接下来重试。</p><p>2PL是一种悲观并发控制机制，SSI是一种乐观并发控制机制。</p><p>为了实现串行化的隔离，数据库必须检测事务是否会修改其他事务的查询结果，并在此情况下，中止事务。也就是SSI等于快照隔离+修改检测机制。</p><p>数据库如何知道查询结果是否发生改变？分两种情况<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>：</p><ul><li>读取之前是否有未提交的写入。</li><li>读取之后是否又有新的写入。</li></ul><h4 id="检测是否都去了过期的MVCC对象">检测是否都去了过期的MVCC对象</h4><p>为防止这种异常，数据库会跟踪那些由于MVCC可见性规则被忽略的写操作。当事务提交时，数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，如果是必须中止当前事务。</p><p>事务43在开始之前有一个未提交的事务42，事务43读取之后，事务42修改了值班人，这导致事务43之前的读取过期了，事务管理器注意到这种情况，及时中止了事务43，并重试。</p><p><img src="read_outdate_mvcc.jpeg" alt="read outdate mvcc"></p><p>为什么要等到提交才检测？因为无法预测当前事务是否有写动作，也无法预料写事务是否成功。</p><h4 id="检测写是否影响了之前的读">检测写是否影响了之前的读</h4><p>第二种要考虑的情况是，在读取数据之后，另一个事务修改了数据。</p><p>和上面类似，事务43在开始之前有一个未提交的事务42，和之前不同的是，之前事务42的修改发生在事务43的读取之前，现在是读取之后，但效果是类似的，事务管理器注意到事务43的读取结果已经发生了改变，只好中止事务并重试。</p><p><img src="read_affected_by_late_write.jpeg" alt="read affected by late write"></p><h4 id="可串行化快照隔离的性能">可串行化快照隔离的性能</h4><p>和2PL相比，SSI不需要加锁。和快照隔离一样，读写不会互相阻塞。使查询延迟更加稳定、可预测。</p><p>与串行化相比，SSI可以突破单个CPU的限制。FoundationDB将冲突检测分布在多台机器上，从而提高总体吞吐量。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>二者是一个意思。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>我感觉这两种情况是一回事啊。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;深入理解事务&quot;&gt;深入理解事务&lt;/h2&gt;
&lt;p&gt;事务将多个读写操作捆绑成一个逻辑整体，要么都成功，要么都失败。&lt;/p&gt;
&lt;h3 id=&quot;ACID&quot;&gt;ACID&lt;/h3&gt;
&lt;p&gt;原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第6章 数据分区</title>
    <link href="https://naosense.github.io/2023/12/19/%E7%AC%AC6%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA/"/>
    <id>https://naosense.github.io/2023/12/19/第6章 数据分区/</id>
    <published>2023-12-19T16:41:16.000Z</published>
    <updated>2025-09-16T02:08:43.000Z</updated>
    
    <content type="html"><![CDATA[<p>面对海量数据集或非常高的查询压力，光有副本还不行，还需要将数据拆分为分区，也称为分片。事实上，分区和副本常常结合起来使用，来提高系统的扩展性和可用性。</p><p><img src="replication_and_partition.jpeg" alt="replication and partition"></p><h2 id="分区方式">分区方式</h2><p>分区的目标是将数据和查询负载均匀分布在所有节点上。</p><p>如果分区不均匀，那就会出现某些分区比其他分区承担更多的数据量或查询负载的情况，称之为<strong>倾斜</strong>。极端情况下，所有的负载可能集中在一个分区上，这种严重不成比例的分区即成为<strong>系统热点</strong>。</p><p>避免热点的一个简单方法是随机分配，但是它的缺点是读取数据时，只能并行查询所有节点。</p><h3 id="基于关键字区间分区">基于关键字区间分区</h3><p>为每个分区分配一段连续的关键字或关键字范围。</p><p><img src="partition_by_range.jpeg" alt="partition by range"></p><p>比如对于一个保存网络传感器数据的应用系统，选择测量的时间戳（年-月-日-时-分-秒）作为关键字，此时区间查询非常有用，可以快速查询某个月份的所有数据。</p><p>缺点是某些访问模式会导致热点。比如上面的例子，每天对应一个分区，数据写入时，所有的写入都会集中在一个分区，而其他分区处于空闲状态。</p><p>解决方案可以在时间戳前面加上传感器名称为前缀。</p><h3 id="基于关键字哈希值分区">基于关键字哈希值分区</h3><p>一个好的哈希函数可以处理数据倾斜。一旦找到合适的哈希函数，就可以为每个分区分配一个哈希范围。</p><p><img src="partition_by_hash.jpeg" alt="partition by hash"></p><p>Cassandra和MongoDB使用MD5，Voldmort使用Fowler-Noll-Vo。许多语言也内置简单的哈希函数，比如Java的<code>hashCode</code>，但是要谨慎使用，因为同一键在不同进程中可能返回不同的哈希值。</p><p>哈希分区的缺点是丧失了区间查询特性。因为即使关键字相邻，哈希之后也是千差万别。</p><p>在MongoDB中，如果启用了哈希分片模式，区间查询会发送到所有的分片上，而Riak、Couchbase和Voldmort干脆就不支持区间查询。</p><p>Cassandra支持多个列组成复合主键，复合主键只有第一部分用于哈希分区，其他列可以区间查询。这种特性对于社交网站上，一个用户可能会发布多个消息更新，关键字为(user_id, update_timestamp)的组合，可以高效的查询。</p><h2 id="二级索引">二级索引</h2><p>二级索引主要挑战是它们不能规整的映射到分区中。</p><h3 id="基于文档分区的二级索引">基于文档分区的二级索引</h3><p>这种方法，每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中的数据。因此文档分区索引也被称为<strong>本地索引</strong>。</p><p><img src="second_index_by_doc.jpeg" alt="second index by doc"></p><p>这种索引查询代价高昂，尽管如此，它还是广泛用于实践：MongoDB、Riak、Cassandra、Elasticsearch、Solr、Voldmort都支持。</p><h3 id="基于词条的二级索引分区">基于词条的二级索引分区</h3><p>对索引数据建立全局索引，为了避免成为瓶颈，全局索引也必须进行分区，但是可以采用与关键词不同的分区策略。</p><p><img src="second_index_by_term.jpeg" alt="second index by term"></p><p>好处是查询更高效，坏处是写入较慢且复杂，因为单个文档更新时，可能会涉及多个二级索引的更新，二级索引的分区又可能在不同的节点上，会引入显著的写放大。因此，现有实现都不支持同步更新，更新往往都是异步的。例如Dynamo二级索引通常可以在1秒内完成更新，但是故障时，可能时间会更长。</p><h2 id="分区再平衡">分区再平衡</h2><p>也就是大家常说的rebalance。这是一项比较昂贵的操作，通常在下面的情况下才做：</p><ul><li>查询压力增加，需要更多的CPU来处理负载。</li><li>数据规模增加，需要更多的内存和磁盘存储数据。</li><li>节点可能出现故障，需要其他机器取接管失效的节点。</li></ul><h3 id="动态再平衡的策略">动态再平衡的策略</h3><p>之所以不用取模的方式分区，是因为节点数量的轻微变化，将会引起分区映射关系的剧烈变动。</p><h4 id="固定数量的分区">固定数量的分区</h4><p>创建远超节点的分区数，然后为每个节点分配多个分区。例如，对于一个10个节点的集群，一开始就划分为1000个分区，每个节点承担100个分区。如果增加了一个新的节点，从现有的节点上匀走一些分区即可，如果删除一个节点，采用相反的均衡措施。</p><p><img src="partition_with_fix_number.jpeg" alt="partition with fix number"></p><p>目前，Riak、Elasticsearch、Couchbase和Voldmort都支持这种方式。</p><p>分区数量一经确定，就不会改变，通常已经考虑到扩容需求。这种分区方式不能适应数据集总规模高度不确定或可变的情况。</p><h4 id="动态分区">动态分区</h4><p>一些数据库，如HBase和RethinkDB采用的方式，当分区数据超过一个可配的阈值（HBase默认是10GB），它就拆分为两个分区，每个承担一半的数据量。相反，会进行分区合并。类似于BTree的分裂和合并操作。</p><p>优点是可以自动适配数据总量。缺点是分区的大小参差不齐，可能会导致长尾效应。</p><p>不仅适用关键字区间分区，还适用于哈希分区。MongoDB从2.4版本，同时支持两者。</p><h4 id="按节点比例分区">按节点比例分区</h4><p>前两种方式分区的数据量与数据集大小成正比。Cassandra和Ketama采用第三种方式，使分区数与节点数成正比，也就是每个节点有固定的分区数。这种方法使分区的大小保持稳定。</p><h4 id="自动与手动再平衡操作">自动与手动再平衡操作</h4><ul><li>全自动，即由系统自动决定何时从一个节点迁移到另一个节点。</li><li>纯手动，即分区到节点的映射由管理员显式配置。</li><li>半自动，由系统自动生成一个分区建议方案，管理员确认。</li></ul><p>无疑，全自动再平衡会更加方便，但是再平衡是一项比较昂贵的操作，操作不当的话会影响某些节点的请求，甚至导致级联式失效，因此让管理员介入可能是个更好地选择。</p><h2 id="请求路由">请求路由</h2><p>这其实属于一类典型的服务发现问题。</p><p>概括来讲，有三种方式：</p><ol><li>客户端请求任意节点。如果节点恰好有需要的分区，直接处理，否则，将请求转发到合适的节点，并将回复转发给客户端。</li><li>客户端请求一个路由层，由后者将请求转发到合适的节点上。</li><li>客户端感知分区和节点分配关系，直接请求某个节点。</li></ol><p><img src="request_route.jpeg" alt="request route"></p><p>Cassandra和Riak节点之间使用gossip协议同步集群状态的变化，类似于上面第1种方式。</p><p>Couchbase采用第2种方式，通过一个名为moxi的路由层，向集群节点学习最新的路由变化。</p><p>LinkedIn的Espresso使用Helix（底层是ZK）进行集群管理，实现了下图所示的请求路由层。HBase、Solr和Kafka也使用ZK来跟踪分区分配情况。MongoDB有类似的设计，但它依赖自己的配置服务器和mongos守护进程来充当路由层。</p><p><img src="request_route_with_zookeeper.jpeg" alt="request route with zookeeper"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;面对海量数据集或非常高的查询压力，光有副本还不行，还需要将数据拆分为分区，也称为分片。事实上，分区和副本常常结合起来使用，来提高系统的扩展性和可用性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;replication_and_partition.jpeg&quot; alt=&quot;replica
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第5章 数据复制</title>
    <link href="https://naosense.github.io/2023/12/15/%E7%AC%AC5%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E5%A4%8D%E5%88%B6/"/>
    <id>https://naosense.github.io/2023/12/15/第5章 数据复制/</id>
    <published>2023-12-15T19:13:26.000Z</published>
    <updated>2025-09-16T02:08:42.992Z</updated>
    
    <content type="html"><![CDATA[<p>本章主要介绍数据复制的技术，问题及挑战，解决方案。</p><p>复制或多副本技术的意义：</p><ul><li>高可用：避免单点故障。</li><li>低时延：将数据放置在靠近用户的地方，从而实现更快的交互。</li><li>扩展性：采用多副本读取，提高系统的吞吐量。</li></ul><h2 id="主从复制（一主多从）">主从复制（一主多从）</h2><p>最主流的复制方案，许多关系数据库都内置支持主从复制，包括PostgreSQL（9.0版本之后）、MySQl、Oracle Data Guard和SQL Server的AlwaysOn Availability Groups，非关系数据库如MongoDB、RethinkDB和Espresso也支持主从复制。还有一些分布式队列如Kafka和RabbitMQ都支持。</p><h3 id="同步复制和异步复制">同步复制和异步复制</h3><p>同步复制的好处是一旦向用户确认，复制已经完成了，缺点是阻塞所有的写操作。异步复制就反过来了。</p><p><img src="sync_or_async_copy.jpeg" alt="sync or async copy"></p><p>不过，同步和异步并不是那么泾渭分明，还有一种<strong>半同步模式</strong>，它的做法是将其中一个副本设置为同步的，其余的为异步，这样至少有两个节点（主节点和这个节点）拥有最新的副本。</p><h3 id="增加新节点">增加新节点</h3><p>快照文件+修改日志的方式</p><h3 id="节点失效">节点失效</h3><p>如果从节点失效，恢复后可以比对日志，追赶主节点。</p><p>如果主节点失效，需要选出一个新的主节点，这个过程称为<strong>切换</strong>。</p><p>切换涉及的步骤：</p><ul><li>探活：一般基于超时的心跳机制。</li><li>选举新的主节点。</li><li>配置系统使新主节点生效。</li></ul><p>典型问题，比如<strong>脑裂</strong>，是说有两个节点都认为自己是主节点的情况。超时时间如何设置，长的话，恢复时间比较长，短的话，会造成不必要的切换。</p><h3 id="具体的复制技术">具体的复制技术</h3><h4 id="基于语句">基于语句</h4><p>比如SQL语句记录，但是会存在如下问题：</p><ul><li>非确定函数，比如<code>NOW()</code>、<code>RAND()</code>，可能会在不同的副本上产生不同的值。</li><li>使用了自增列，或者依赖现有数据，例如UPDATE … WHERE。</li><li>有副作用的语句，比如触发器、存储过程、用户定义的函数等，可能会在不同的副本上产生不同的副作用。</li></ul><h4 id="基于预写日志（WAL）">基于预写日志（WAL）</h4><p>比较偏底层，一个WAL包含了哪些磁盘块的哪些字节发生变化，诸如此类的细节。</p><h4 id="基于行的逻辑日志">基于行的逻辑日志</h4><p>逻辑日志与具体存储引擎解耦，更有利于向后兼容性。</p><ul><li>行插入，日志包含所有列的新值。</li><li>行删除，日志里有行的唯一标识，通常为主键，如果表没有主键，就包含所有列的旧值。- 行更新，日志里包含行的唯一标识，和列的所有新值。</li></ul><p>MySQL的binlog（配置为行复制）就属于这一类。</p><h3 id="复制滞后问题">复制滞后问题</h3><blockquote><p>使用最终一致性系统时，最好事先就思考这样的问题：如果复制延迟增加到几分钟甚至几小时，那么应用层的行为会是什么样子？如果答案是“没问题”，那没得说，否则就得考虑提供一个比最终一致性强的保证。</p></blockquote><h4 id="读自己的写">读自己的写</h4><p>用户在写入不久即查看数据，新数据还未到达从节点。对用户来讲，看起来似乎刚才提交的数据丢失了。对于这种情况，需要“写后读一致性”。</p><p><img src="read_after_write.jpeg" alt="read after write"></p><p>典型方案：</p><ul><li>用户访问可能会修改的内容，从主节点读取，否则，从从节点读取。比如，社交网络的个人主页从主节点读，他人主页从从节点读。</li><li>跟踪最新的修改时间，如果是一分钟之内，从主节点读取。</li><li>如果副本分布在多数据中心，需要先把请求路由到主节点所在的数据中心。</li></ul><p>如果允许用户多设备登录，还需要考虑：</p><ul><li>更新时间戳需要做到全局共享。</li><li>多数据中心部署的应用，还要将多设备的请求都路由到主节点所在的数据中心。</li></ul><h4 id="单调读">单调读</h4><p>用户看到了新内容后，又读到了过期的内容，好像时间回拨，此时需要单调一致性。这是一个比强一致性弱，又比最终一致性强的保证。</p><p><img src="monotonic_read.jpeg" alt="monotonic read"></p><p>实现方式之一是，确保用户总是固定的从某个节点读取，比如对用户id进行哈希。</p><h4 id="前缀一致读">前缀一致读</h4><p>必须先看到“问题”，再看到“回答”，而不能反过来，这种保证叫做前缀一致读。</p><p><img src="consistent_prefix_read.jpeg" alt="consistent prefix read"></p><p>一个解决方案，确保任何具有因果顺序关系的写入都交给一个分区来完成，但该方案真实实现效率会大打折扣。</p><h4 id="基于触发器">基于触发器</h4><p>可以配置自定义代码在某种事件下。</p><p>灵活性最高，性能最差。</p><h2 id="多主节点复制">多主节点复制</h2><p>主从复制有主节点单点故障的缺陷，因此自然有人想到设置多个主节点，每个主节点都可以接受写入，被写入的主节点再将数据同步给其他主节点。</p><p>使用场景：</p><ul><li>多数据中心</li><li>离线客户端操作，比如日历软件，一个设备就相当于一个数据中心。</li><li>协作编辑，每个正在编辑用户都是一个数据中心。</li></ul><h3 id="处理写冲突">处理写冲突</h3><p>多主的一大问题是<strong>写冲突</strong>。</p><p><img src="configs_in_multiple_master.jpeg" alt="configs in multiple master"></p><p>一种方法是避免冲突，比如将修改的请求都路由到特定的数据中心。</p><p>第二种方法是使状态收敛于一致的状态。具体实现方法：</p><ul><li>给每个写入都分配一个唯一的ID，比如时间戳、一个比较长的随机数，挑选最高的ID获胜，这种技术被称为<strong>最后写入者获胜</strong>（last write wins, LWW）。</li><li>以某种方式合并值。比如上文中，合并的标题类似于“B/C”。</li><li>利用预定义的格式保存所有值，提示用户解决冲突，类似于git，和cf。</li></ul><h3 id="拓扑结构">拓扑结构</h3><p>环形、星形、全部-至-全部。</p><p><img src="multi-leader_topology.jpeg" alt="multi-leader topology"></p><p>环形、星形有中间节点单点故障问题，全部-至-全部由于每个主节点的延时不同，有类似于前缀读的问题。</p><p><img src="arrive_wrong_order_in_multi-leader.jpeg" alt="arrive wrong order in multi-leader"></p><p>对于多主节点复制，某些副本上可能会出现错误的写请求到达顺序，可以使用版本向量解决。</p><h2 id="无主节点复制">无主节点复制</h2><p>放弃主节点，允许任何副本直接接受来自客户端的写请求。一些实现是客户端直接将请求发送给多副本，另一些实现，由一个协调者代表客户端写入。</p><p>代表产品：Dynamo、Riak、Cassandra、Voldemort，因为Dynamo后面几种都是受Dynamo启发设计的，所以称之为<strong>Dynamo风格数据库</strong>。</p><p>失效节点重新上线后的两种处理机制：</p><ul><li>读修复。客户端读取多个副本时，检测到掉线节点版本较旧，就用新值更新。这种方法适合频繁读取的场景。</li><li>反熵。后台进程不断查找副本之间的差异，将缺少的数据从一个副本复制到另一个副本。</li></ul><p><img src="read_repair.jpeg" alt="read repair"></p><h3 id="读写quorum">读写quorum</h3><p>如果有n个副本，写入需要w个节点确认，读取需要r个节点确认，w + r &gt; n，读取的节点中一定包含最新值。</p><p>当一个集群的节点大部分失效，已经无法满足仲裁的需求，这个时候面临着：</p><ul><li>直接向用户报错。</li><li>将请求导向一些临时节点，等恢复后再将数据回传回来，这些节点不属于原来的n个节点。</li></ul><p>后一种措施就是<strong>宽松的（sloppy）quorum</strong>。</p><p>所有的Dynamo风格的数据库都支持sloppy quorum。Riak默认启用，Cassandra和Voldemort默认关闭。</p><p><img src="dynamo_wrong_order.jpeg" alt="dynamo wrong order"></p><h3 id="检测并发写">检测并发写</h3><p>一种实现最终收敛的方法是最后写入者获胜LWW。但LWW会导致数据丢失问题。</p><p>在分布式环境中并发的含义是两个操作没有依赖关系，比如happen-before。基于此，两个操作A和B只有三种关系，A在B之前发生，B在A之前发生，A和B并发。依赖关系可以覆盖，并发不能覆盖。</p><p>对于不能覆盖的情况，需要合并值。方法是一种基于<strong>版本向量</strong>的算法。</p><p><img src="version_vector.jpeg" alt="version vector"></p><p>以两个客户端并行操作购物车为例，它的算法运行步骤如上图所示：</p><ol><li>客户端A首先添加了milk，服务器返回(version: 1, value: [milk])。</li><li>客户端B随后添加了eggs，服务器返回(version: 2, value: [eggs])和(version: 1, value: [milk])，客户端将值进行合并，并选择所有值最高的版本号，(version: 2, value: [eggs, milk])。</li><li>接着客户端A又添加了flour，注意他是在version1的基础上添加的，因此他发给服务器的是(version: 1, value: [milk, flour])，服务器意识到version1的值得到了更新，所以覆盖老的值，最终返回(version: 3, value: [milk, flour])和(version: 2, value: [eggs])，客户端A收到值进行合并(version: 3, value: [milk, flour, eggs])。</li><li>接着客户端B也添加了新的物品ham，和步骤3类似，他是在version2的基础上添加的，也就是发给服务器的是(version: 2, value: [eggs, milk, ham])，服务器更新version2的值，最终返回(version: 4, value: [eggs, milk, ham])和(version: 3, value: [milk, flour])，客户端B合并值，得到(version: 4, value: [eggs, milk, ham, flour])。</li><li>这时客户端A又添加了bacon，也就是在version3的基础上加上bacon——(version: 3, value: [milk, flour, eggs, bacon]，服务器覆盖version3的值，返回(version: 5, value: [milk, flour, eggs, bacon])和(version: 4, value: [eggs, milk, ham]，客户端A最终得到(version: 5, value: [milk, flour, eggs, bacon, ham])。</li></ol><p>上面示例的因果关系如下所示。</p><p><img src="relations_between_evens.jpeg" alt="relations between evens"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本章主要介绍数据复制的技术，问题及挑战，解决方案。&lt;/p&gt;
&lt;p&gt;复制或多副本技术的意义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高可用：避免单点故障。&lt;/li&gt;
&lt;li&gt;低时延：将数据放置在靠近用户的地方，从而实现更快的交互。&lt;/li&gt;
&lt;li&gt;扩展性：采用多副本读取，提高系统的吞吐
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第4章 数据编码与演化</title>
    <link href="https://naosense.github.io/2023/12/13/%E7%AC%AC4%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E6%BC%94%E5%8C%96/"/>
    <id>https://naosense.github.io/2023/12/13/第4章 数据编码与演化/</id>
    <published>2023-12-13T14:52:14.000Z</published>
    <updated>2025-09-16T02:08:42.989Z</updated>
    
    <content type="html"><![CDATA[<p>本章对比了JSON、Thrift、Protocol Buffer、Avro几种编码方式在模式演进时如何保持兼容性，更好的支持程序滚动升级。随后列举了几种进程间数据交互的方式，这些交互方式利用之前介绍的数据编码方案保持服务的兼容性。</p><ul><li>向后兼容：较新的代码可以读取较旧的代码编写的数据，新代码兼容旧数据</li><li>向前兼容：旧代码兼容新数据</li></ul><p>一般而言，向后兼容比较容易，因为编写新代码时，清楚旧数据的格式。</p><h2 id="数据编码格式">数据编码格式</h2><p>程序数据两种表示形式：</p><ul><li>内存中的数据结构。</li><li>为了写入文件或网络传输的字节序列。</li></ul><p>前者转为后者称为<strong>编码</strong>（也称序列化），后者转为前者称为<strong>解码</strong>（也称反序列化）。</p><h3 id="语言特定的格式">语言特定的格式</h3><h3 id="JSON和XML">JSON和XML</h3><pre><code class="language-json">&#123;    &quot;userName&quot;: &quot;Martin&quot;,    &quot;favoriteNumber&quot;: 1337,    &quot;interests&quot;: [&quot;daydreaming&quot;, &quot;hacking&quot;]&#125;</code></pre><p>文本形式，易读性强，开发调试友好，数字编码有模糊之处，缺少模式，占用空间大。</p><h3 id="Thrift和Protocol-Buffer">Thrift和Protocol Buffer</h3><p>Thrift有两种编码格式，为BinaryProtocol和CompactProtocol。Protocol Buffer常被称为pb，只有一种编码方式，和Thrift的CompactProtocol非常类似。由于Thrift和Protocol Buffer二者非常类似，因此下面只介绍pb。</p><p>接口定义语言（IDL）描述模式</p><pre><code>message Person &#123;    required string user_name       = 1;    optional int64 favorite_number  = 2;    repeated string interests       = 3;&#125;</code></pre><p><img src="pb_encode.jpeg" alt="pb encode"></p><p>模式随着时间不断变化，称为<strong>模式演化</strong>。</p><p>添加新字段时，向前兼容通过忽略不认识的字段实现，向后兼容不能添加必填（required）字段。删除字段时向前和向后兼容性和添加字段时相反。这意味着只能删除非必填字段，而且之前的字段标签不能再用，免得老代码写入的数据被够被新代码忽略。</p><p>数据类型改变在某些方式是支持的，比如pb的单值到多值的互转，但是面临着潜在的数据丢失问题。</p><blockquote><p>pb相比json占用空间更小的原因</p><ul><li>使用字段标签（tag）代替了字段名。</li><li>紧凑的二进制编码，避免了文本编码的许多元字符，比如逗号，引号。</li><li>使用可变长度的int编码整型字段（varint，字节最高位标识是否还有下一个字节），进一步降低了空间占用。</li></ul></blockquote><h3 id="Avro">Avro</h3><p>Avro是Hadroop孵化出得一个项目，广泛地用在Hadroop生态中。</p><p>当应用程序想要对某些数据进行编码，它使用所知道的模式模式的任何版本来编码数据，这被称为<strong>写模式</strong>。当应用程序想要解码某些数据，它期望数据符合某个模式，即<strong>读模式</strong>。</p><p><img src="avro_encode.jpeg" alt="avro encode"></p><p>Avro的关键思想是，写模式和读模式不必是完全一模一样，它们只需保持兼容。例如，写模式和读模式字段顺序不同，这也没有问题，因为模式解析通过字段名匹配（这里不太懂，编码的时候没有将字段名编码进去，那解码是如何根据字段名匹配呢？）。如果一个字段写模式有读模式没有，则忽略，反之，则用默认值填充。</p><p><img src="avro_models.jpeg" alt="avro models"></p><p>相比pb和thrift，avro对动态模式支持更好。</p><p>总结下，二进制编码的好处：</p><ul><li>比json这种文本格式更紧凑，因为省略了字段名称。</li><li>模式是一种强制的自描述的文档<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>。</li><li>更好的向前兼容和向后兼容。</li><li>静态语言可以通过代码生成获得编译时类型检查。</li></ul><h2 id="进程间数据流动">进程间数据流动</h2><h3 id="基于数据库的数据流">基于数据库的数据流</h3><p>这种方式或许是大家见得最多，使用得最多的一种方式了。也就是应用程序将数据库当作中转站，将数据写入，并在之后读取写入的数据，通常会涉及多种不同功能的服务以及众多的接口。</p><h3 id="基于服务的数据流：REST和RPC">基于服务的数据流：REST和RPC</h3><p>服务器公开的API称为<strong>服务</strong>。</p><p>将大型应用程序按照功能分解为较小的服务，当一个服务需要另一个服务的功能或数据时，就会向另一个服务发出请求。这种构建应用程序的方式被称为<strong>面向服务的体系架构</strong>（service-oriented architecture，SOA），或者<strong>微服务体系结构</strong>（microservices architecture）。</p><p>微服务体系的一个关键设计目标是，通过使服务可独立部署和演化，让应用程序更易于修改和维护。</p><p>当HTTP为用作底层通信协议时，它被称为<strong>Web服务</strong>。有两种流行的Web服务方法：REST和SOAP。</p><p>REST不是一种协议，而是一个基于HTTP原则的设计理念。它强调简单的数据格式，使用URL标识资源，并使用HTTP功能进行缓存控制、身份验证和内容类型协商。根据REST原则设计的API称为RESTful。</p><p>SOAP是一种基于XML的协议，用于发出网络API请求。虽然它最常用于HTTP，但其目的是独立于HTTP，并避免使用大多数HTTP功能。相反，它带有庞大而复杂的多种相关标准（Web服务框架，Web Service Framework，称为WS-*）和新增的各种功能。SOAP Web服务的API被称作WSDL（Web Service Description Language）来描述。</p><p>SOAP消息复杂，严重依赖工具支持、代码生成和IDE，不同厂商实现之间标准不一。RESTful倾向于更简单的方法，涉及较少的自动化工具和代码生成，受到小公司的青睐。</p><blockquote><p>到底什么是REST？</p><p>REST全称Resource Representational State Transfer，资源表现层状态转移。这名字越听越让人糊涂，它的真正意思是用url标识资源位置，用HTTP动词（GET/POST/DELETE/PUT）表示操作，用HTTP状态码标识访问状态。<br>它的一些最佳实践：</p><ul><li>使用名词，而不是动词，且推荐名词复数。<pre><code>BAD/getProducts/listOrders/retrieveClientByOrder?orderId=1GOODGET /products : will return the list of all productsPOST /products : will add a product to the collectionGET /products/4 : will retrieve product #4PATCH/PUT /products/4 : will update product #4</code></pre></li><li>保证HEAD和GET是安全的，不改变资源状态。</li><li>资源地址采用嵌套结构，例如<code>GET /friends/10375923/profile</code></li></ul><p>这样做地好处是啥呢？</p><ul><li>看url就知道请求的什么资源。</li><li>看method就知道要干什么。</li><li>看状态码就知道结构如何。</li></ul></blockquote><h3 id="基于消息传递的数据流">基于消息传递的数据流</h3><p>与RPC相比，使用消息代理有几个优点：</p><ul><li>接受方不可用或过载，消息代理可以充当缓冲区，也就是常说的削锋作用。</li><li>自动重发，防止消息丢失。</li><li>避免了发送方需要知道接受方的ip和端口。</li><li>支持一条消息发送给多个接受方。</li><li>逻辑上将发送方和接受方分离，也就是解耦作用。</li></ul><p>消息传递是单向的，RPC通常是双向的，消息是fire-and-forget。</p><p>两种实现：</p><ul><li>消息代理，也就是MQ。</li><li>分布式Actor模型。</li></ul><p>分布式Actor框架的实质是将消息代理和Actor模型集成到单个框架中。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>这一点的重要性相信调过别人接口的人都知道，当你使用一个json接口，很难有人能说清这个json会包含哪些字段，更比提每个字段的意义了。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本章对比了JSON、Thrift、Protocol Buffer、Avro几种编码方式在模式演进时如何保持兼容性，更好的支持程序滚动升级。随后列举了几种进程间数据交互的方式，这些交互方式利用之前介绍的数据编码方案保持服务的兼容性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;向后兼容：较新的
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第3章 数据存储与检索</title>
    <link href="https://naosense.github.io/2023/12/06/%E7%AC%AC3%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2/"/>
    <id>https://naosense.github.io/2023/12/06/第3章 数据存储与检索/</id>
    <published>2023-12-06T19:07:37.000Z</published>
    <updated>2025-09-16T02:08:42.982Z</updated>
    
    <content type="html"><![CDATA[<p>本章主要讲了数据库存储涉及到的核心数据结构，以及数据库两种主要的应用场景：OLTP和OLAP。</p><h2 id="核心数据结构">核心数据结构</h2><blockquote><p>在最基本的层面，数据库只需做两件事：向它插入数据时，它保存数据；之后查询时，它返回数据</p></blockquote><p>数据存储两种形式：追加和原地修改。<strong>索引</strong>是为了提高查询速度的额外数据结构。</p><h3 id="哈希索引">哈希索引</h3><p>典型产品：Bitcask。</p><ul><li>内存侧：hashmap索引，key为查询的键，value为文件中数据偏移量。</li><li>磁盘侧：真正的数据文件存储在磁盘上。</li></ul><blockquote><p>为什么进行日志分段？</p><p>书中说为了避免用尽磁盘空间。我当时看了很纳闷，不分段，也就是一直往一个文件写，边写边检测文件大小是否小于磁盘剩余空间不就完了？为什么非得分段？请教了下chatgbt，给出了三个理由：</p><ol><li>磁盘碎片化：长时间持续写入一个文件会导致磁盘碎片化，即文件被分散存储在物理磁盘的不同位置。</li><li>文件扩展：文件会持续增长，没有合适的管理，会耗尽磁盘空间（这不废话吗）。</li><li>日志管理：分成一定大小的段文件可以更好的管理日志。当文件达到一定大小时，关闭它并将后续写入到新的段文件中，可以使得日志的查找、备份、传输等操作更加方便和高效。</li></ol><p>我又纳闷了，为什么长时间写入一个文件会碎片化，分段就不会？还有文件扩展，你边写边检测不就行了？<br>chatgbt给出的解答：</p><ol><li>关于碎片化：持续写入一个文件时，磁盘上连续的可用空间可能不足以一次性写入整个文件，这倒是，文件越大，能够连续写入的概率越小。</li><li>边写边检测的方法是可行的，但是可靠性不如分段。比如，如果写入速度过快，检测文件大小频率太低，仍然会导致文件大小超过磁盘的情况。此外，写入文件时可能会出现错误或异常，导致无法正确检测文件大小的情况，导致数据丢失。分段的思想有点类似造船的时候设置的多个水密仓，单个仓损坏，船舶仍然可控，控制了数据损毁的影响范围。</li></ol></blockquote><p>追加日志的好处：</p><ul><li>顺序写比随机写高效得多。</li><li>并发和崩溃恢复简单得多。</li><li>合并旧段可以避免碎片化。</li></ul><p>哈希索引缺点：</p><ul><li>必须全部放入内存，如果有大量的键，内存存不下就不行了。</li><li>区间查询效率不高。</li></ul><h3 id="SSTables和LSM-Tree">SSTables和LSM-Tree</h3><p>将段文件中的key-value对按键排序就是<strong>排序字符串表</strong>（SSTables）。相比哈希索引的日志段，具有以下优点：</p><ol><li>合并更加简单有效。因为段文件已经按照key排序，合并多个段时，只需依次比较段的第一个键，然后将最小的放置在输入文件中，重复这一过程即可完成合并。</li><li>在文件中查找键时，不再需要在内存中保存<strong>所有键的</strong>索引，只需维护一个保存有部分键的稀疏索引。比如查找键handiwork，但是知道handbag和handsome的偏移量，根据键的顺序特性，handiwork的偏移量肯定位于handbag和handsome之间。</li><li>读取的时候因为往往要扫描多个key-value，可以将这些key-value对保存在一个块中，稀疏索引指向块的开头，更好的利用磁盘读取的局部性。对块还可以压缩合并，节省磁盘空间，还能减少磁盘IO带宽的占用。</li></ol><p><img src="sparse_index.jpeg" alt="sparse_index"></p><blockquote><p>稀疏索引如何查找key？</p><p>稀疏索引是按照键排序好的，查找指定key时，可以采用二分法查找小于等于key的值，拿上面的示例来说，查找handiwork时，索引中没有handiwork，因此会查出来handbag，以handbag为起点查找，段文件中如果查不到那就是没有这个key，在leetcode上很常见的类型，算法复杂度log(n)。</p></blockquote><p>SSTable构建和维护<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p><ul><li>写入时，添加到内存中的平衡树数据结构（也称<strong>内存表</strong>），比如红黑树。</li><li>当内存表大于某个阈值（通常为几兆字节）将其作为SSTables写入磁盘。</li><li>读时先在内存表中查找，然后查找最新的磁盘段文件，然后是次新的段文件，依次类推。</li><li>后台进程周期性的合并和压缩段文件。</li><li>为了避免数据崩溃时数据丢失，可以在磁盘上保留单独的日志，每个写入都会立即追加到这个日志，该日志不需要排序，它的唯一目的就是恢复内存表。</li></ul><blockquote><p>内存索引和内存表</p><p>在SSTables的语境下，前者是为了快速定位SSTables在磁盘上的数据块，后者是新写入但未持久化到磁盘暂存在内存中的数据部分。</p></blockquote><p><strong>LSM-Tree</strong>（Log-Structured Merge-Tree）日志结构的合并树，基于合并和压缩排序文件原理的存储引擎通常都被称为<strong>LSM存储引擎</strong>。</p><p>性能优化：</p><ul><li>当键查不到时，需要扫描内存表和多个段文件，效率很低，可以引入布隆过滤器来改善这一状况。</li><li>大小分级和分层压缩。LevelDB和RocksDB使用分层压缩，HBase使用大小分级，Cassandra同时支持这两种方式。</li></ul><h3 id="B-tree">B-tree</h3><p>B-tree以固定大小的页为单位，传统大小为4KB，页是内部读写的最小单位，相比之下SSTable数据块是数据的逻辑分割单位。</p><p>B-tree一个页的子叶数量称为<strong>分支因子</strong>。</p><p>在插入时，如果一个页已经满了，就会<strong>分裂</strong>为两个半满的页。</p><p><img src="btree_split.jpeg" alt="btree_split"></p><blockquote><p>B树和B+树</p><ul><li>节点结构：B树节点存储键值对，B+树只有叶子节存储值，中间节点只存键，这样分支因子更高，树的高度更低，从而减少了磁盘访问次数。</li><li>叶子节点之间的连接：B+树增加了叶子节点之间的连接，提高了范围查找的效率。</li></ul></blockquote><p><strong>预写日志</strong>（write-ahead log，WAL）是为了让数据块能从奔溃中恢复设置的额外的数据结构。</p><p>B-tree的优化措施：</p><ul><li>不再用覆盖页和WAL了进行崩溃恢复，而是写时复制（也就是和java的CopyOnWrite数据结构类似的思想）。</li><li>使用键的缩略信息，而不是完整的键。</li><li>将相邻叶子页按顺序存在磁盘上，提高数据的局部性。</li><li>叶子之间的指针（上文B+树那里提过了）。</li><li>分形树等变体。</li></ul><blockquote><p>根据经验，LSM-Tree写时快，B-tree读时快。</p></blockquote><p>总结，LSM-tree特点：</p><ul><li>写入吞吐高。</li><li>碎片少，数据紧凑，磁盘占用少。</li><li>压缩会影响写入。</li></ul><p>B-tree的特点：</p><ul><li>事务支持好（在实现中，通过范围锁定键进行事务隔离）。</li><li>每个键对应唯一的索引位置。</li></ul><h3 id="其他索引结构">其他索引结构</h3><h4 id="聚集索引">聚集索引</h4><p>在索引结构中，可以存数据（行）的引用，也可以存数据本身，如果后一种，这种索引就称为<strong>聚集索引</strong>（也叫<strong>聚簇索引</strong>）。</p><p>在MySQL中主键索引是聚集索引，二级索引引用主键，在查找时多了一次从普通列到主键的检索过程。</p><h4 id="多列索引">多列索引</h4><p>也叫<strong>多维索引</strong>，是为了提高多列数据条件查找的速度。在使用这种索引时，要考虑左端匹配。</p><h4 id="全文索引和模糊搜索">全文索引和模糊搜索</h4><p>之前介绍的索引，都是精确匹配的索引，而全文索引必须得支持对同义词，或者疏忽导致拼写错误进行检索，比如Lucene支持在某个编辑距离内搜索文本，采用的是字符序列生成一个有限状态机，可以高效的搜索单词。</p><h4 id="内存数据库">内存数据库</h4><p>我们常说的缓存就属于这一类，比如Redis、Memcached，数据完全保存在内存中，有些会提供弱的持久化。</p><blockquote><p>作者提到：</p><p>与直觉相反，内存数据库的性能优势并不是因为它们不需要从磁盘读取。如果有足够的内存，即使是基于磁盘的存储引/擎，也可能永远不需要从磁盘读取，因为操作系统将最近使用的磁盘块缓存在内存中。相反，内存数据库可以更快，是因为它们避免使用写磁盘的格式对内存数据结构编码的开销。</p><p>“它们避免使用写磁盘的格式对内存数据结构编码的开销”就是那些对数据进行的序列化、压缩和持久化等操作，比如json想存在磁盘上，要不存成文本，要不经过protobuffer序列化，也就是所谓的“编码”，才能存在磁盘上。</p></blockquote><h2 id="OLTP和OLAP">OLTP和OLAP</h2><p><strong>OLTP</strong>（online transaction processing）根据用户的输入添加或更新记录，由于这些应用是交互式的，所以称为<strong>在线事务处理</strong>。</p><blockquote><p>事务不一定具体ACID属性。事务处理只是意味着允许客户端进行低延迟读取和写入，是相对批处理而说的（难道交互式的非自动化批处理的就可称之为事务？）。</p></blockquote><p><strong>OLAP</strong>（online analytic processing），数据库越来越多的用于数据分析，这些分析通常由业务分析师编写，为了给管理层提供更好决策的报告，为了和OLTP区分，称为<strong>在线分析处理</strong>。</p><h3 id="数据仓库">数据仓库</h3><p>对于大型公司，为了避免对在线服务的影响，都有自己专门的数据仓库，OLTP数据库经过ETL（Extract-Transform-Load，提取-转换-加载）生成OLAP数据库（数据仓库）（我之前就在一家公司使用PL/SQL干过这个活）。</p><p>有两种主流的分析数据模型：星形和雪花型分析模式。</p><p>所谓<strong>星形模型</strong>，是说中间有一个非常宽（通常超过100列）的<strong>事实表</strong>，围绕着它衍生出来许多<strong>维度表</strong>（只用到事实表中的几列），这些连接就像星星的光茫，因此得名。</p><p><img src="star_model.jpeg" alt="star_model"></p><p>而<strong>雪花模式</strong>是星形的更丰富版本，维度进一步细分为子空间（雪花是一种分形结构，它有六个分支，可以无限递归）。</p><h3 id="列式存储">列式存储</h3><p>创建维度表时，大部分时候只用到了事实表的几列，每次将整行读出来是对资源的巨大浪费，很自然地就有人就想到了按列存储。</p><blockquote><p>比如Parquet是基于Google Dremel的一种支持文档数据库的列存储格式</p></blockquote><p>面向列的存储依赖一系列列文件，里面顺序保存着列数据。一整行通过拼接列文件<strong>同一个索引位置</strong>的数据组成，比如取23行，将列文件23位置的数据拼接起来。</p><h4 id="列压缩">列压缩</h4><p>列式存储有大量重复值，非常适合压缩。</p><p>使用位图存储。</p><blockquote><p>所谓位图就是列的每个不同值（假设为M）使用一个序列，通常是一个数组，序列的的长度等于列长（假设为N），根据列的值是否等于当前序列的值进行标记，比如1代表等于，0代表不等于，最终形成一个M x N的二维数据结构。</p></blockquote><p><img src="bitmap_index.jpeg" alt="bitmap_index"></p><p>位图的优点：</p><ul><li>压缩重复值，节省空间。</li><li>加速过滤和条件查询：可以快速指示数据中符合条件的行。</li><li>支持高效的AND/OR操作：也就是便于计算机<strong>矢量化处理</strong>。</li></ul><h4 id="列排序">列排序</h4><p>排序后最直接的好处就是便于查询。</p><p>列排序后相同的值聚集在一起，更利于压缩，比如转为位图后，所有值都是0/1，再使用<strong>游程编码</strong>，即便几十亿行的表也可以压缩到几千字节。</p><p>上面位图的游程编码。</p><pre><code>product_sk = 29:    9, 1            (9 zeros, 1 one, rest zeros)product_sk = 30:    10, 2           (10 zeros, 2 one, rest zeros)product_sk = 31:    5, 4, 3, 3      (5 zeros, 4 ones, 3 zeros, 3 ones, rest zeros)product_sk = 68:    15, 1           (15 zeros, 1 one, rest zeros)product_sk = 69:    0, 4, 12, 2     (0 zeros, 4 one, 12 zeros, 2 ones)product_sk = 74:    4, 1            (4 zeros, 1 one, rest zeros)</code></pre><p>通常为了适配多种查询，会存储数据的多个排序副本，这一思想最早由商业数据仓库Vertica所采用。</p><h4 id="数据立方体和物化视图">数据立方体和物化视图</h4><p><strong>物化视图</strong>其实就是特定查询的一个缓存，这样每次查询不用从零开始，速度更快。</p><p><strong>数据立方体</strong>是物化视图的一种实现，它是不同维度的聚合网格。比如下面事实表只包含两个维度：日期（date_key)和产品（product_key），绘制一个二维表。每个单元格是date-product组合的事实表属性（图中为net_price），沿着行或列聚合，得到一个<strong>减少一个维度</strong>的总和。</p><p><img src="data_cube.jpeg" alt="data_cube"></p><p>对于多维的事实表类似，比如有五个维度：日期、产品、商店、促销和客户。这意味着会生成一个五个维度的立方体，五个维度的值自由组合，比如单个维度如日期，两个维度（日期，产品），三个维度（日期，产品，客户）……。</p><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>LevelDB和RocksDB的算法大致就是这样的，主要用于嵌入到其他应用程序的key-value存储引擎库。类似的存储引擎库还被用于Cassandra和HBase，这两个引擎都受到Google的Bigtable论文的启发。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本章主要讲了数据库存储涉及到的核心数据结构，以及数据库两种主要的应用场景：OLTP和OLAP。&lt;/p&gt;
&lt;h2 id=&quot;核心数据结构&quot;&gt;核心数据结构&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;在最基本的层面，数据库只需做两件事：向它插入数据时，它保存数据；之后查询时，它返回
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第2章 数据模型和查询语言</title>
    <link href="https://naosense.github.io/2023/11/30/%E7%AC%AC2%E7%AB%A0%20%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80/"/>
    <id>https://naosense.github.io/2023/11/30/第2章 数据模型和查询语言/</id>
    <published>2023-11-30T18:42:23.000Z</published>
    <updated>2025-09-16T02:08:42.980Z</updated>
    
    <content type="html"><![CDATA[<p>本章主要讲了数据模型，以及围绕模型所构建的查询语言。</p><h2 id="数据模型">数据模型</h2><h3 id="关系模型">关系模型</h3><blockquote><p>由Edgar Codd与1977年提出，这种模型将数据组织成关系（relations），在SQL中称为表（table），其中每个关系都是元组（tuples）的无序集合，也就是SQL中的行。</p></blockquote><p>MySQL、Oracle、PostgreSQL等一众大家耳熟能详的数据库都属于此类。适用于：</p><ul><li>结构一致的数据。</li><li>事务性要求比较高的情况，比如金融、银行等领域。</li></ul><h3 id="文档模型">文档模型</h3><p>所谓文档模型就是可以直接存储json、xml等非结构化数据，数据的关系和模式不再是首要关注的对象。相关的产品有Redis、MongoDB、HBase等等。</p><blockquote><p>NoSQL<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>：不仅仅是SQL</p><p>最初作为一个标签出现在2009年的开源、分布式以及非关系数据库的见面会上。</p></blockquote><p>NoSQL的优势：</p><ul><li>扩展性更好，支持超大数据集或超高吞吐量。</li><li>大部分是免费开源，成本优势。</li><li>查询的局部性更好，也就是一次将所有数据都查出来了，不用做联结和子查询。</li><li>更具动态和表达力的数据模型，和应用程序数据结构比较接近，减少了阻抗失谐<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</li></ul><h4 id="树模型">树模型</h4><p>一个示例，下面是比尔盖茨个人简历的json描述：</p><pre><code class="language-json">&#123;    &quot;user id&quot;: 251,    &quot;first_name&quot;: &quot;Bill&quot;,    &quot;last_ name&quot;: &quot;Gates&quot;,    &quot;summary&quot;: &quot;Co-chair of the Bill &amp; Melinda Gates... Active blogger.&quot;,    &quot;region id&quot;: &quot;us:91&quot;,    &quot;industry_id&quot;: 131,    &quot;photo ur1&quot;: &quot;/p/7/000/253/05b/308dd6e.jpg&quot;,    &quot;positions&quot;: [        &#123;&quot;job_title&quot;: &quot;Co-chair&quot;, &quot;organization&quot;: &quot;Bill &amp; Melinda Gates Foundation&quot;&#125;,    &#123;&quot;job_title&quot;: &quot;Co-founder, Chairman&quot;, &quot;organization&quot;: &quot;Microsoft&quot;&#125;    ],    &quot;education&quot;: [        &#123; &quot;school_name&quot;: &quot;Harvard University&quot;, &quot;start&quot;: 1973, &quot;end&quot;: 1975 &#125;,    &#123; &quot;school_name&quot;: &quot;Lakeside School, Seattle&quot;, &quot;start&quot;: null, &quot;end&quot;: null &#125;    ],    &quot;contact info&quot;: &#123;    &quot;blog&quot;: &quot;http://thegatesnotes.com&quot;,    &quot;twitter&quot;: &quot;http://twitter.com/BillGates&quot;    &#125;&#125;</code></pre><p>画成图是这个样子。</p><img alt="tree model" src="tree_model.jpeg" width=500><p>可以看到是一层一层的，像一棵树，所以有时候也称为层次模型或树模型。</p><p>其实json并非没有模式，只是和关系模型相比，一个是写式模式（显式），一个读时模式（隐式），json格式更易修改，不用像关系数据库得修改表结构。</p><p>json拥有更好的局部性，不用联接（join）多张表或者多次查询，但仅限于访问大部分数据情况，无法像关系数据库返回特定字段。</p><p>json擅长处理1 vs N，不擅长处理N vs 1和N vs N。想支持只能在应用层使用代码做，另外是不是还增加了数据冗余度，因为不能像关系数据库那样通过外键引用同一份数据。</p><h4 id="网络模型">网络模型</h4><p>不像层次模型，每个记录只有一个父节点，网络模型可以有多个父节点，比如“大西雅图地区”可能是一个记录，居住在该地区的用户都指向它，因此可以方便的支持多对一和多对多。</p><p>比如这个多对多的例子。</p><p><img src="net_model.jpeg" alt="net model"></p><blockquote><p>融合数据库</p><p>关系数据库和文档数据库呈现出融合趋势，主流的关系数据库PostgreSQL、MySQL、DB2已经支持json、xml等常用文档类型。文档数据库RethinkDB查询接口支持和关系型类似的联结，MongoDB驱动程序可以自动解析数据库的引用关系。</p></blockquote><h3 id="图状数据模型">图状数据模型</h3><p>关系模型可以勉为其难的处理多对多，但是还是图模型更自然。</p><p>图有两种对象构成：顶点和边，典型的例子：</p><ul><li>社交网络：顶点是人，边指示哪些人彼此认识。</li><li>Web图：顶点是网页，边表示网页之间的超链接。</li><li>公路或铁路网：顶点是交叉口，边表示它们之间的公路线或铁路线。</li></ul><p>一个示例，来自社交网络的族谱数据库，来自爱达荷州的Lucy和来自法国波恩的Alain，他们结婚了，目前住在伦敦。</p><p><img src="graph_model.jpeg" alt="graph model"></p><p>图模型最大的特点就是灵活，它的灵活性来自于：</p><ul><li>任何顶点之间都可以连接。</li><li>给定某个顶点，可以高效的得到它的入边和出边，从而遍历图。</li><li>可以在同一张图的同一顶点之间标记不同的标签来表达不同的关系，同时仍然保持图的整洁。</li></ul><p>图数据模型可以使用关系数据库和三元存储实现。</p><h4 id="关系数据表">关系数据表</h4><p>如果是关系数据表实现，相应地可以用SQL查询，但是写起来比专门的图查询语言麻烦多了。</p><pre><code class="language-sql">CREATE TABLE vertices (    vertex_id   interger PRIMARY KEY,    properties  json);CREATE TABLE edges (    edge_id     integer PRIMARY KEY,    tail_vertex integer REFERENCE vertices (vertex_id),    head_vertex integer REFERENCE vertices (vertex_id),    label       text,    properties  json);CREATE INDEX edges_tails ON edges (tail_vertex);CREATE INDEX edges_heads ON edges (head_vertex);</code></pre><h4 id="三元组">三元组</h4><p>几乎等同于属性图模型，所有信息都表示为（主体，谓语，客体）。例如，（吉姆，喜欢，香蕉）。三元组的主体相当于图的顶点，客体可能是：</p><ul><li>属性值，比如（lucy，age，33）。</li><li>顶点，比如（lucy，marriedTo，alain）。</li></ul><p>以Turtle<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup>三元组的形式表示图：</p><pre><code>@prefix : &lt;urn:example:&gt;._:lucy      a :Person;          :name &quot;Lucy&quot;;          :bornIn _:idaho._:idaho     a :Location;        :name &quot;Idaho&quot;;         :type &quot;state&quot;;   :within _:usa._:usa       a :Location;        :name &quot;United States&quot;; :type &quot;country&quot;; :within _:namerica. :namerica  a :Location;        :name &quot;North America&quot;; :type &quot;continent&quot;.</code></pre><p>RDF（Resource Description Framework）是一种基于xml的资源描述框架，目的是为不同的网站定义一种通用格式，这样不同的网站可以自动合并成一个数据网络，一种互联网级别包含一切数据的数据库。</p><p>我个人觉得Turtle是给人看的三元组，RDF是给机器看的三元组。</p><blockquote><p>语义网</p><p>语义网源自大家想创建一种囊括互联网所有数据的大数据库的设想，为了创建这种数据库，需要所有人都遵守一种通用格式，就像人为了能够理解彼此，必须得说同样地语言，为了描述这种格式诞生了RDF。</p></blockquote><p>在可预见的未来，大多数系统会同时使用关系数据库和NoSQL数据库，称为<strong>混合持久化</strong>。</p><h2 id="数据查询语言">数据查询语言</h2><h3 id="命令式">命令式</h3><p>需要告诉程序一步一步怎么做，大多数的编程语言都属于此类。</p><h3 id="声明式">声明式</h3><p>告诉程序做什么即可，具体怎么做程序自主决定，如SQL、web中的css和xsl。</p><h4 id="SQL">SQL</h4><p>比如使用SQL查询每个月看到了多少鲨鱼。</p><pre><code class="language-sql">SELECT date_trunc('month', observation_timestamp) AS observation_month,       sum(num_animals) as total_animalsFROM observationsWHERE family = 'Shark'GROUP BY observation_month;</code></pre><h4 id="聚合管道">聚合管道</h4><p>MongoDB 2.2增加了聚合管道的声明式查询语言，相当于SQL的子集，基于json语法。它的等效表达如下：</p><pre><code>db.observations.aggregate(    &#123; $match: &#123; family: &quot;Shark&quot; &#125; &#125;,    &#123; $group: &#123;        _id: &#123;            year: &#123; $year: &quot;observationTimestamp&quot; &#125;,            month: &#123; $month: &quot;observationTimestamp&quot; &#125;        &#125;,        totalAnimal: &#123; $sum: &quot;$numAnimals&quot; &#125;    &#125;);</code></pre><p>感觉某种程度上，可以看成是文档数据库的SQL语言。</p><h4 id="Cypher">Cypher</h4><p>Cypher查询语言，一种属性图的声明式查询语言，最早为Neo4j图形数据库而创建。比如，使用Cypher查询从美国移民到欧洲的人员名单：</p><pre><code>MATCH    (person) -[BORN_IN]-&gt; () -[:WITHIN*O..]-&gt; (us:Location &#123;name:'United States'&#125;).    (person) -[LIVES_IN]-&gt; () -[:WITHIN*O..]-&gt; (eu:Location &#123;name:'Europe'&#125;).</code></pre><h4 id="SPARQL">SPARQL</h4><p>SPARQL（发音：sparkle），是一种基于RDF的查询语言。比如，执行同样的查询，比Cypher<br>更加简洁<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。</p><pre><code>SELECT ?personName WHERE &#123;    ?person :name ?personName.    ?person :bornIn / :within* / :name &quot;United States&quot;.    ?person :liveIn / :within* / :name &quot;Europe&quot;.&#125;</code></pre><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>又仔细看了下书，NoSQL是相对SQL（关系模型）而说的，应该不仅包括文档模型，还包含之后的图模型。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>编程语言中是一些对象，而关系数据库基本单元是行和列，模型之间的这种脱离称为阻抗失谐。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>Turtle是Notation3的子集。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>简不简洁见仁见智，但是看起来更像SQL倒是真的。 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;本章主要讲了数据模型，以及围绕模型所构建的查询语言。&lt;/p&gt;
&lt;h2 id=&quot;数据模型&quot;&gt;数据模型&lt;/h2&gt;
&lt;h3 id=&quot;关系模型&quot;&gt;关系模型&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;由Edgar Codd与1977年提出，这种模型将数据组织成关系（relations
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>第1章 可靠、可扩展与可维护的应用系统</title>
    <link href="https://naosense.github.io/2023/11/28/%E7%AC%AC1%E7%AB%A0%20%E5%8F%AF%E9%9D%A0%E3%80%81%E5%8F%AF%E6%89%A9%E5%B1%95%E4%B8%8E%E5%8F%AF%E7%BB%B4%E6%8A%A4%E7%9A%84%E5%BA%94%E7%94%A8%E7%B3%BB%E7%BB%9F/"/>
    <id>https://naosense.github.io/2023/11/28/第1章 可靠、可扩展与可维护的应用系统/</id>
    <published>2023-11-28T17:21:45.000Z</published>
    <updated>2025-09-16T02:08:42.979Z</updated>
    
    <content type="html"><![CDATA[<p>当前的许多系统都是<strong>数据密集型应用</strong>（data-intensive），已经不再受限于CPU，关键在于数据量、数据的复杂度以及数据的快速多变为特性。比如大型电商如淘宝、京东，新闻推送如腾讯、凤凰网，社交平台如twitter、facebook等等，都属于这一类型。</p><p><img src="image.jpeg" alt="image"></p><p>基本构成组件：</p><ul><li>数据库</li><li>高速缓存</li><li>索引：根据关键字快速检索</li><li>流式处理：比如一些flink任务，或者自定义的worker承接来自MQ的消息，进行相关的数据处理</li><li>批处理：定时任务</li></ul><p>数据系统的三个方面：</p><ul><li>可靠性</li><li>可扩展性</li><li>可维护性</li></ul><h2 id="可靠性">可靠性</h2><p>可靠性大家天天挂到嘴边，用大白话说其实就是有点小风小浪，甚至中风中浪，系统是否稳定，书面一点，就是系统在遇到局部故障时，仍能维持服务的能力。</p><p>比如一些典型的场景：</p><ul><li>参数输入错误</li><li>流量突然增加了一倍</li><li>分布式部署的某个机房突然挂掉了</li><li>黑客入侵</li></ul><p>遇到这些情况，系统能不能很好的应对。</p><blockquote><p>故障（fault）和失效（failure）</p><p>前者强调组件偏离规格，强调单体和局部，后者强调整体和全局，也就是说整个服务已经没法提供服务了。但事实上，大家在日常工作中区分不了那么精细，而且说法也不尽相同，书中提出这一概念，是为了说明<strong>100%可靠的系统是不存在的</strong>，系统的容错是有限度的，并不是所有的故障系统都能够容忍。</p></blockquote><p>故障应对措施：</p><ul><li>硬件故障：冗余备份，比如RAID、UPS电源。</li><li>软件错误：难以预料，更加隐蔽，只能充分的测试，报警和可观测系统。</li></ul><p>可靠性很重要，但并不是绝对的。比如银行和普通的web服务对可靠性要求肯定不一样，甚至同一个系统的不同模块对可靠性要求也不尽相同，通常在线的可靠性要求要高于离线系统。</p><h2 id="可扩展性">可扩展性</h2><p>系统规模的增长，比如流量、数据量，相应的系统资源如何增加。</p><p>在日常工作中很常见，比如阿里、京东这样的电商公司在大促的时候面对流量激增通常的方案就是扩容，那到底扩多少呢？在降本增效的背景下，老板经常会问“能不能优化下，不用增加机器”，因为机器都是实实在在的钱呢。这个说起来容易，其实挺难的，因为系统资源增长并不一定是线性的，但实际工作中都是按照线性来评估，或者使用压测来决定。</p><p><strong>负载</strong>通常使用<strong>吞吐量</strong>进行描述，在线系统常用QPS来衡量，离线系统可能是单位时间处理的<strong>数据量</strong>来衡量。</p><p>性能的话，使用性能指标的分位值来衡量，比如avg、p50、p99。书中说“avg掩盖了一些信息，无法告诉有多少用户实际经历了多少延迟”，实际上大部分情况下，avg和p50是非常接近的，avg的缺点是容易受异常值影响。比如100个请求，99个请求的延时都是50ms左右，剩下一个请求5000ms，那么平均下来，延时接近100ms。</p><p>通常衡量性能时，会同时使用avg和p99，一个说明平均情况，一个说明长尾情况。</p><blockquote><p>长尾效应</p><p>一个服务涉及多个不同的后端调用，则最慢的调用会拖累整个服务相应时间。</p><p>比如分布式部署的服务，可能会涉及多个机器的相应，这些机器有快又慢。又比如推荐系统中不同用户的画像有多有少，多的自然相应就慢一些。这些都有可能造成长尾效应。</p></blockquote><p>关于分位值的两种解释，以p99为例：</p><ol><li>将延时按照从小到大排列，第99%*n（n为请求数）的延时大小。</li><li>100个请求中，有99个请求的延迟是小于p99的，也就是一个请求小于p99的概率是99%。</li></ol><blockquote><p>延迟（latency）和响应时间（response time）</p><p>延迟是系统服务的时间。响应时间是客户端看到的时间，除了服务时间，还有网络来回的延迟。平常上下游服务指标对不上，可能就是没有区分延迟和响应时间，但通常内网里延迟也就毫秒级。</p></blockquote><p>扩容方式：</p><ul><li>垂直扩容：使用更好的机器</li><li>水平扩容：使用更多的机器</li></ul><p>一般小公司或初创公司倾向于使用垂直扩容，而中大型公司倾向于使用水平扩容，或者二者兼而有之，具体还是得看成本、业务增长速度等因素。</p><h2 id="可维护性">可维护性</h2><p>一说维护，首先想到的可能就是运维，其实这里的维护性是指系统容不容易改，新功能容不容易上，出了问题容不容易排查和解决，不光涉及运维。</p><p>涉及到三个原则：</p><ul><li>可运维性</li><li>简单性</li><li>可演化性</li></ul><h3 id="可运维性">可运维性</h3><p>运营团队能够方便的保持系统平稳运行。</p><h3 id="简单性">简单性</h3><p>简而言之，就是<strong>控制复杂度</strong>。</p><p>对于自己的小项目，你可以把代码写的简洁而优美，对于多人参与的公司级项目，复杂度常常会超出控制，相信大家都见识过这种“屎山”代码。</p><p>作者列举了几种表现形式，说的太好了，我必须全文摘录下来：</p><ul><li>状态空间的膨胀：这种情况很好理解，随着代码越来越多，所要处理的情况越来越多，状态空间肯定越来越多。</li><li>模块紧耦合：比如随着人员的流动，最初的设计原则已经无人知晓，导致原本不该依赖的模块依赖了。</li><li>令人纠结的相互依赖关系</li><li>不一致的命名和术语：比如有的使用英文命名，有的使用拼音，即便有时候都使用英文大家翻译的也是五花八门。</li><li>为了性能而采取的特殊处理：这一条和下一条差不多，都是一些特例处理，如果你不是当事人，不了解背景，就很难了解代码的逻辑。</li><li>为了解决特定问题而引入的特殊框架：比如为什么有了grpc还要引入brpc，为什么有了protobuffer还要引入thrift，类似的框架同时出现在系统中</li></ul><p>作者给出了解决复杂度的方法是<strong>抽象</strong>。但真正想做好并不那么容易，会受人员经验、需求紧迫度、公司政策等因素影响。</p><blockquote><p>一个真实的例子</p><p>公司一名同学修改别人的代码导致线上出现错误，并因此复盘，后来，再遇到这种情况，这名同学都是复制一份代码再改，这样至少不会影响线上现有功能，但是代码的冗余度增加了。</p></blockquote><h3 id="可演化性">可演化性</h3><p>是不是容易改变，比如容易修改原来的老功能，容易添加新功能。</p><p>这一点和简单性密切相关，因为简单的系统更容易修改。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;当前的许多系统都是&lt;strong&gt;数据密集型应用&lt;/strong&gt;（data-intensive），已经不再受限于CPU，关键在于数据量、数据的复杂度以及数据的快速多变为特性。比如大型电商如淘宝、京东，新闻推送如腾讯、凤凰网，社交平台如twitter、facebook等等，
      
    
    </summary>
    
    
      <category term="分布式" scheme="https://naosense.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
      <category term="读书笔记" scheme="https://naosense.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
      <category term="ddia" scheme="https://naosense.github.io/tags/ddia/"/>
    
      <category term="系统设计" scheme="https://naosense.github.io/tags/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"/>
    
      <category term="大数据" scheme="https://naosense.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
  </entry>
  
  <entry>
    <title>Git最小命令集</title>
    <link href="https://naosense.github.io/2023/11/24/Git%E6%9C%80%E5%B0%8F%E5%91%BD%E4%BB%A4%E9%9B%86/"/>
    <id>https://naosense.github.io/2023/11/24/Git最小命令集/</id>
    <published>2023-11-24T18:51:18.000Z</published>
    <updated>2025-09-16T02:08:42.958Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景">背景</h2><p>git命令有点多，选项就更多了，别说初学者无所适从，作为老鸟，如果长期使用ui界面操作，或者一段时间不用命令行也是晕头转向。我呢，就是常年使用idea的ui界面操作git，突然切换vscode，界面和操作方式和之前idea不太一样，用起来很不适应，只好重新把命令行学起来。命令行有一个好处，无论是vscode，还是idea，抑或是其他的什么ide，都可以“一招吃遍”。</p><h2 id="前提">前提</h2><p>大部分企业通常仓库会有一个主分支master，大家基于主分支拉取自己的开发分支，修改代码，然后提交，最后合并到master分支。</p><h2 id="常规流程">常规流程</h2><p>常规流程基本上就是：创建分支——&gt;更新代码——&gt;提交代码——&gt;删除分支。</p><h3 id="创建分支">创建分支</h3><pre><code class="language-bash"># 查看本地分支git branch# 创建本地分支并切换git branch branch_name origin/mastergit checkout branch_name# 或者一步到位git checkout -b branch_name origin/master</code></pre><h3 id="更新代码">更新代码</h3><p>除非个人仓库可以使用<code>git pull origin master</code>，其他多人合作的代码库，我建议一律采用先fetch后rebase的方式更新代码。</p><pre><code class="language-bash"># 拉取最新代码git fetch origin master# 查看本地当前代码与远程主库区别，如果只想看commit，去掉-pgit log -p HEAD..origin/master# 将当前代码变基到远程主库上git rebase origin/master</code></pre><p>如果代码rebase有冲突，先解决冲突，然后执行继续变基。</p><pre><code class="language-bash">git rebase --continue</code></pre><h3 id="提交代码">提交代码</h3><pre><code class="language-bash">git statusgit add some_code_filesgit commit -m &quot;commit message&quot;git push</code></pre><h3 id="删除分支">删除分支</h3><pre><code class="language-bash"># 删除本地分支git branch -d branch_name# 忽略未合并的commit强制删除本地分支git branch -D branch_name# 删除远端分支git push origin :branch_name</code></pre><h2 id="其他命令">其他命令</h2><h3 id="回退版本">回退版本</h3><pre><code class="language-bash"># 上个版本git reset HEAD^# 上两个版本git reset HEAD^^# 或git reset HEAD~1git reset HEAD~2</code></pre><p>回退到某个commit</p><pre><code class="language-bash"># commit id前7位git reset 69fde2c</code></pre><h3 id="美化commit记录">美化commit记录</h3><p>如果写着写着，突然发现有个代码在上一commit中忘了添加了，想追加进去，那可以使用</p><pre><code class="language-bash">git add forgot_file# 如果是最后一条可以用git commit -m &quot;commit msg&quot; --amend# 如果这些commit已经推送到远端了，要使用force推送覆盖git push --force-with-lease</code></pre><p>如果写代码写的比较忘我，提交的也不亦乐乎，可能会形成许多零碎的commit，看着很不美观，这时候你可以</p><pre><code class="language-bash"># 修改最后n个提交git rebase -i HEAD~n# 如果这些commit已经推送到远端了，要使用force推送覆盖git push --force-with-lease</code></pre><h3 id="查看文件或文件夹的变动记录">查看文件或文件夹的变动记录</h3><pre><code class="language-bash">git log -p -- src/main.cppgit log -p -- src/some_path</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;git命令有点多，选项就更多了，别说初学者无所适从，作为老鸟，如果长期使用ui界面操作，或者一段时间不用命令行也是晕头转向。我呢，就是常年使用idea的ui界面操作git，突然切换vscode，界面和操作方式和之前idea不太一样，用
      
    
    </summary>
    
    
      <category term="github" scheme="https://naosense.github.io/tags/github/"/>
    
      <category term="git" scheme="https://naosense.github.io/tags/git/"/>
    
  </entry>
  
  <entry>
    <title>一套全平台多端发布hexo博文的方法</title>
    <link href="https://naosense.github.io/2023/11/21/%E4%B8%80%E5%A5%97%E5%85%A8%E5%B9%B3%E5%8F%B0%E5%A4%9A%E7%AB%AF%E5%8F%91%E5%B8%83hexo%E5%8D%9A%E6%96%87%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>https://naosense.github.io/2023/11/21/一套全平台多端发布hexo博文的方法/</id>
    <published>2023-11-21T18:51:10.000Z</published>
    <updated>2025-09-16T02:08:42.961Z</updated>
    
    <content type="html"><![CDATA[<p>hexo博客建了好久了，一直以来都有几个痛点：</p><ul><li>只能电脑发布。在手机日期流行的今天还挺要命的，有时候上一天班真心不想开电脑，电脑不能随时随地使用，比如地铁上。</li><li>图片的插入不方便。需要找图床，或者保存在同名文件夹中，然后手动再插入markdown文档。</li><li>换电脑需要重复配置hexo环境，每次都要安装一次nodejs以及一堆依赖，特别是后端程序员，使用nodejs不多，时间一长都忘了咋配置，每次都得百度一番。</li></ul><p>最近在twitter上受@lencx_启发，发现一套可以全平台多端发布hexo博文的方法，方案如下：</p><ol><li>使用github discussion作为数据源，天然支持分类和tag，还有天生的版本管理功能，如果注重隐私，还可以选择私密仓库。</li><li>当发布或修改discussion时，使用github api将discussion同步下来，生成markdown文档。</li><li>使用github action创建hexo部署环境，将markdown发布成博文。</li></ol><p>github有手机端，支持ios和android，支持上传图片，网页端也是相当的好用，github action透明发布，不用再关心部署环境。</p><p>大家也可以举一反三，使用这种方式，同步发布公众号什么的。</p><p>整体github action配置为</p><pre><code class="language-yml">name: deploy discussion to hexo blogon:  # init workflow  # push:  #  branches:  #    - source  discussion:    types: [created, edited]env:  # change env here  GITHUB_NAME: naosense  GITHUB_EMAIL: pingao777@gmail.com  GH_TOKEN: $&#123;&#123; secrets.GH_TOKEN &#125;&#125;  ACTION_DEPLOY_KEY: $&#123;&#123; secrets.HEXO_DEPLOY_SECRET &#125;&#125;jobs:  sync:    name: Build    runs-on: ubuntu-latest    steps:      - name: Checkout        uses: actions/checkout@v4        with:          ref: 'source'      - name: Set up Python        uses: actions/setup-python@v4        with:          python-version: 3.11.4      - name: Get pip cache dir        id: pip-cache        run: |          echo &quot;dir=$(pip cache dir)&quot; &gt;&gt; $GITHUB_OUTPUT      - name: pip cache        uses: actions/cache@v3        with:          path: $&#123;&#123; steps.pip-cache.outputs.dir &#125;&#125;          key: $&#123;&#123; runner.os &#125;&#125;-pip-$&#123;&#123; hashFiles('**/requirements.txt') &#125;&#125;          restore-keys: |            $&#123;&#123; runner.os &#125;&#125;-pip-      - name: Install python dependencies        run: |          python -m pip install --upgrade pip          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi        if: steps.pip-cache.outputs.cache-hit != 'true'      - name: Check discussion if is ready        id: check_discussion        run: |          python deploy.py      - name: Set up Node.js        uses: actions/setup-node@v4        with:          node-version: 16.19.0          cache: 'npm'      - name: Install hexo and dependencies        run: |          npm install -g hexo-cli          npm install      - name: Hexo deploy and Commit md file        run: |          mkdir -p ~/.ssh/          echo &quot;$ACTION_DEPLOY_KEY&quot; &gt; ~/.ssh/id_rsa          chmod 600 ~/.ssh/id_rsa          ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts          git config --global user.email &quot;$&#123;&#123; env.GITHUB_EMAIL &#125;&#125;&quot;          git config --global user.name &quot;$&#123;&#123; env.GITHUB_NAME &#125;&#125;&quot;          git add source/_posts          git commit -m 'sync from discussion' \          &amp;&amp; git push \          &amp;&amp; hexo douban \          &amp;&amp; hexo deploy -g \          &amp;&amp; echo &quot;Done, congrats!&quot; \          || echo &quot;Oops, something wrong!&quot;</code></pre><p>有几点需要注意：</p><ol><li>需要使用secret配置一个token，变量名为<code>GH_TOKEN</code>，用来调用github api。</li><li>需要生成一个ssh key，用来部署hexo，配置方法参考<a href="https://makefile.so/2021/11/28/use-github-actions-to-deploy-hexo-blog/">ssh配置</a>。</li></ol><p>这样，你就可以愉快地在地铁里，在被窝里……等任何地方写博客了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;hexo博客建了好久了，一直以来都有几个痛点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只能电脑发布。在手机日期流行的今天还挺要命的，有时候上一天班真心不想开电脑，电脑不能随时随地使用，比如地铁上。&lt;/li&gt;
&lt;li&gt;图片的插入不方便。需要找图床，或者保存在同名文件夹中，然后手动再插入m
      
    
    </summary>
    
    
      <category term="github" scheme="https://naosense.github.io/tags/github/"/>
    
      <category term="hexo" scheme="https://naosense.github.io/tags/hexo/"/>
    
  </entry>
  
</feed>
